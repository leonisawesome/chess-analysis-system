#!/usr/bin/env python3
"""
Complete Chess File Renaming System with Full v5 Analyzer Integration + IDF Weighting + Quarantine Deletion + Progress Bars
ALL CODE INCLUDED - COMPLETE INTEGRATED SYSTEM v5.1 - ENHANCED WITH PROGRESS TRACKING
Total system for analyzing and renaming 67,000+ chess files with enhanced IDF weighting, safe quarantine deletion, and comprehensive progress tracking
"""

import os
import json
import logging
import hashlib
import sqlite3
import shutil
import unicodedata
import re
import math
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Set
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import argparse
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed, ThreadPoolExecutor
import traceback
import csv
import time
from collections import defaultdict, Counter
import mimetypes
import numpy as np

# Progress bar imports - NEW v5.1
try:
    from tqdm import tqdm
    from tqdm.contrib.concurrent import thread_map, process_map

    TQDM_AVAILABLE = True
except ImportError:
    print("Warning: tqdm not available. Install with: pip install tqdm")
    TQDM_AVAILABLE = False


    # Fallback progress indicator
    class tqdm:
        def __init__(self, iterable=None, total=None, desc=None, **kwargs):
            self.iterable = iterable
            self.total = total or (len(iterable) if iterable else 0)
            self.desc = desc
            self.n = 0
            if desc:
                print(f"Starting: {desc}")

        def __iter__(self):
            for item in self.iterable:
                yield item
                self.update(1)

        def __enter__(self):
            return self

        def __exit__(self, *args):
            if self.desc:
                print(f"Completed: {self.desc}")

        def update(self, n=1):
            self.n += n
            if self.total and self.n % max(1, self.total // 20) == 0:
                percent = (self.n / self.total) * 100
                print(f"Progress: {self.n}/{self.total} ({percent:.1f}%)")

        def set_description(self, desc):
            self.desc = desc

        def set_postfix(self, postfix_dict):
            pass  # Ignore postfix in fallback

        def close(self):
            pass

# NLP imports for v5 analyzer
try:
    import torch
    from transformers import AutoTokenizer, AutoModel, pipeline
    from sentence_transformers import SentenceTransformer, util
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.feature_extraction.text import TfidfVectorizer

    NLP_AVAILABLE = True
except ImportError as e:
    print(f"Missing NLP libraries: {e}")
    print("Install with: pip install torch transformers sentence-transformers scikit-learn")
    NLP_AVAILABLE = False


# ====================================================================================================
# IDF-ENHANCED WEIGHTING SYSTEM - v5.1 FEATURE WITH PROGRESS TRACKING
# ====================================================================================================

@dataclass
class IDFWeights:
    """Container for IDF weights calculated from corpus analysis"""
    term_weights: Dict[str, float]
    total_documents: int
    vocabulary_size: int
    calculation_date: str
    corpus_hash: str


class IDFCalculator:
    """Calculate IDF weights from document corpus for enhanced semantic analysis - Enhanced with Progress Tracking"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def calculate_corpus_idf(self, documents: List[str], chess_concepts: Dict[str, List[str]]) -> IDFWeights:
        """Calculate IDF weights with progress tracking and interruption handling"""
        self.logger.info(f"Calculating IDF weights for {len(documents)} documents")

        # Flatten all chess terms
        all_terms = []
        for category, terms in chess_concepts.items():
            all_terms.extend([term.lower() for term in terms])

        self.logger.info(f"Analyzing {len(all_terms)} unique chess terms across corpus")

        # Count document frequencies with progress bar
        term_doc_counts = Counter()
        total_docs = len(documents)

        with tqdm(total=total_docs, desc="ðŸ” Analyzing documents for IDF calculation",
                  unit="docs", miniters=max(1, total_docs // 100)) as pbar:

            for doc_idx, document in enumerate(documents):
                try:
                    doc_lower = document.lower()
                    doc_terms = set()

                    # Find terms present in this document
                    for term in all_terms:
                        if term in doc_lower:
                            doc_terms.add(term)

                    # Count each unique term once per document
                    for term in doc_terms:
                        term_doc_counts[term] += 1

                    # Update progress
                    pbar.update(1)

                    # Update description with current stats every 100 docs
                    if doc_idx % 100 == 0 and doc_idx > 0:
                        unique_terms_found = len([t for t in term_doc_counts.values() if t > 0])
                        pbar.set_description(f"ðŸ” Doc {doc_idx}/{total_docs} | {unique_terms_found} terms found")

                except Exception as e:
                    self.logger.warning(f"Error processing document {doc_idx}: {e}")
                    continue

        # Calculate IDF weights with progress
        self.logger.info("Computing IDF weights from document frequencies...")
        term_weights = {}

        with tqdm(total=len(all_terms), desc="ðŸ“Š Computing IDF weights", unit="terms") as pbar:
            for term in all_terms:
                doc_freq = term_doc_counts[term]
                if doc_freq > 0:
                    # Add smoothing to prevent division by zero
                    idf = math.log((total_docs + 1) / (doc_freq + 1))
                    term_weights[term] = idf
                else:
                    # Term not found in any document - assign high weight
                    term_weights[term] = math.log(total_docs + 1)

                pbar.update(1)

        # Create corpus hash for validation
        self.logger.info("Creating corpus validation hash...")
        corpus_text = " ".join(documents[:100])  # Sample for hashing
        corpus_hash = hashlib.md5(corpus_text.encode()).hexdigest()

        weights = IDFWeights(
            term_weights=term_weights,
            total_documents=total_docs,
            vocabulary_size=len(term_weights),
            calculation_date=datetime.now().isoformat(),
            corpus_hash=corpus_hash
        )

        avg_idf = sum(term_weights.values()) / len(term_weights)
        self.logger.info(f"IDF calculation complete: {len(term_weights)} terms, avg IDF: {avg_idf:.3f}")

        return weights

    def save_idf_weights(self, weights: IDFWeights, filepath: str):
        """Save IDF weights to file"""
        with open(filepath, 'w') as f:
            json.dump(asdict(weights), f, indent=2)
        self.logger.info(f"IDF weights saved to {filepath}")

    def load_idf_weights(self, filepath: str) -> Optional[IDFWeights]:
        """Load IDF weights from file"""
        try:
            with open(filepath, 'r') as f:
                data = json.load(f)

            weights = IDFWeights(
                term_weights=data['term_weights'],
                total_documents=data['total_documents'],
                vocabulary_size=data['vocabulary_size'],
                calculation_date=data['calculation_date'],
                corpus_hash=data['corpus_hash']
            )

            self.logger.info(f"IDF weights loaded: {weights.vocabulary_size} terms from {weights.calculation_date}")
            return weights
        except Exception as e:
            self.logger.error(f"Failed to load IDF weights: {e}")
            return None


# ====================================================================================================
# QUARANTINE DELETION SYSTEM - v5.1 FEATURE WITH PROGRESS TRACKING
# ====================================================================================================

@dataclass
class QuarantineManifest:
    """Manifest for files moved to quarantine"""
    quarantine_id: str
    creation_date: str
    deletion_threshold: int
    total_files: int
    total_size_bytes: int
    files: List[Dict[str, Any]]
    recovery_instructions: str


class QuarantineManager:
    """Manage quarantine operations for safe file deletion - Enhanced with Progress Tracking"""

    def __init__(self, base_quarantine_dir: str = "chess_quarantine"):
        self.base_quarantine_dir = Path(base_quarantine_dir)
        self.logger = logging.getLogger(__name__)

    def create_quarantine_session(self, deletion_threshold: int) -> str:
        """Create new quarantine session directory"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        quarantine_id = f"evs_below_{deletion_threshold}_{timestamp}"

        quarantine_path = self.base_quarantine_dir / quarantine_id
        quarantine_path.mkdir(parents=True, exist_ok=True)

        self.logger.info(f"Created quarantine session: {quarantine_id}")
        return quarantine_id

    def move_files_to_quarantine(self, files_to_quarantine: List[Dict],
                                 quarantine_id: str, deletion_threshold: int) -> QuarantineManifest:
        """Move files to quarantine with detailed progress tracking"""
        quarantine_path = self.base_quarantine_dir / quarantine_id
        manifest_files = []
        total_size = 0
        moved_count = 0

        self.logger.info(f"Moving {len(files_to_quarantine)} files to quarantine...")

        with tqdm(total=len(files_to_quarantine), desc="ðŸ—‚ï¸ Moving files to quarantine",
                  unit="files") as pbar:

            for i, file_info in enumerate(files_to_quarantine):
                try:
                    source_path = Path(file_info['original_path'])
                    if not source_path.exists():
                        self.logger.warning(f"Source file not found: {source_path}")
                        pbar.update(1)
                        continue

                    # Update progress description with current file
                    pbar.set_description(f"ðŸ—‚ï¸ Moving: {source_path.name[:30]}")

                    # Preserve directory structure in quarantine
                    try:
                        relative_path = source_path.relative_to(source_path.anchor)
                    except ValueError:
                        relative_path = source_path.name

                    dest_path = quarantine_path / "files" / relative_path
                    dest_path.parent.mkdir(parents=True, exist_ok=True)

                    # Move file
                    shutil.move(str(source_path), str(dest_path))

                    # Record in manifest
                    file_size = dest_path.stat().st_size
                    manifest_files.append({
                        'original_path': str(source_path),
                        'quarantine_path': str(dest_path),
                        'evs_score': file_info.get('evs_score', 0),
                        'content_quality': file_info.get('content_quality', 0.0),
                        'game_type': file_info.get('game_type', 'unknown'),
                        'file_size': file_size,
                        'moved_date': datetime.now().isoformat()
                    })

                    total_size += file_size
                    moved_count += 1

                    pbar.update(1)

                    # Update stats in description every 10 files
                    if moved_count % 10 == 0:
                        pbar.set_description(
                            f"ðŸ—‚ï¸ Moved {moved_count}/{len(files_to_quarantine)} files ({total_size / 1024 / 1024:.1f} MB)")

                except Exception as e:
                    self.logger.error(f"Failed to quarantine {file_info.get('original_path', 'unknown')}: {e}")
                    pbar.update(1)
                    continue

        # Create manifest
        manifest = QuarantineManifest(
            quarantine_id=quarantine_id,
            creation_date=datetime.now().isoformat(),
            deletion_threshold=deletion_threshold,
            total_files=moved_count,
            total_size_bytes=total_size,
            files=manifest_files,
            recovery_instructions=f"Use 'python chess_system.py --restore-quarantine {quarantine_id}' to recover files"
        )

        # Save manifest
        manifest_path = quarantine_path / "manifest.json"
        with open(manifest_path, 'w') as f:
            json.dump(asdict(manifest), f, indent=2)

        self.logger.info(f"Quarantine complete: {moved_count} files ({total_size / 1024 / 1024:.1f} MB)")
        return manifest

    def restore_from_quarantine(self, quarantine_id: str) -> bool:
        """Restore files from quarantine back to original locations"""
        quarantine_path = self.base_quarantine_dir / quarantine_id
        manifest_path = quarantine_path / "manifest.json"

        if not manifest_path.exists():
            self.logger.error(f"Quarantine manifest not found: {manifest_path}")
            return False

        try:
            with open(manifest_path, 'r') as f:
                manifest_data = json.load(f)

            files_to_restore = manifest_data['files']
            files_restored = 0

            with tqdm(total=len(files_to_restore), desc="ðŸ“¤ Restoring from quarantine", unit="files") as pbar:
                for file_info in files_to_restore:
                    try:
                        quarantine_file = Path(file_info['quarantine_path'])
                        original_path = Path(file_info['original_path'])

                        pbar.set_description(f"ðŸ“¤ Restoring: {original_path.name[:30]}")

                        if quarantine_file.exists():
                            # Ensure destination directory exists
                            original_path.parent.mkdir(parents=True, exist_ok=True)

                            # Move back to original location
                            shutil.move(str(quarantine_file), str(original_path))
                            files_restored += 1

                        pbar.update(1)
                        pbar.set_postfix({'Restored': files_restored})

                    except Exception as e:
                        self.logger.error(f"Failed to restore {file_info['original_path']}: {e}")
                        pbar.update(1)

            self.logger.info(f"Restored {files_restored} files from quarantine {quarantine_id}")

            # Clean up empty quarantine directory
            if files_restored > 0:
                try:
                    shutil.rmtree(quarantine_path)
                except:
                    pass

            return files_restored > 0

        except Exception as e:
            self.logger.error(f"Failed to restore quarantine {quarantine_id}: {e}")
            return False

    def list_quarantines(self) -> List[Dict[str, Any]]:
        """List all available quarantine sessions"""
        if not self.base_quarantine_dir.exists():
            return []

        quarantines = []
        for quarantine_dir in self.base_quarantine_dir.iterdir():
            if quarantine_dir.is_dir():
                manifest_path = quarantine_dir / "manifest.json"
                if manifest_path.exists():
                    try:
                        with open(manifest_path, 'r') as f:
                            manifest_data = json.load(f)

                        quarantines.append({
                            'id': quarantine_dir.name,
                            'creation_date': manifest_data['creation_date'],
                            'total_files': manifest_data['total_files'],
                            'total_size_mb': manifest_data['total_size_bytes'] / 1024 / 1024,
                            'deletion_threshold': manifest_data['deletion_threshold']
                        })
                    except Exception as e:
                        self.logger.warning(f"Failed to read quarantine manifest {quarantine_dir}: {e}")

        return sorted(quarantines, key=lambda x: x['creation_date'], reverse=True)

    def auto_purge_old_quarantines(self, max_age_days: int = 30):
        """Automatically purge quarantines older than specified days"""
        if not self.base_quarantine_dir.exists():
            return

        cutoff_date = datetime.now() - timedelta(days=max_age_days)
        purged_count = 0

        quarantines_to_check = list(self.base_quarantine_dir.iterdir())

        if quarantines_to_check:
            with tqdm(quarantines_to_check, desc="ðŸ§¹ Checking quarantines for purge", unit="sessions") as pbar:
                for quarantine_dir in quarantines_to_check:
                    pbar.set_description(f"ðŸ§¹ Checking: {quarantine_dir.name[:30]}")

                    if quarantine_dir.is_dir():
                        manifest_path = quarantine_dir / "manifest.json"
                        if manifest_path.exists():
                            try:
                                with open(manifest_path, 'r') as f:
                                    manifest_data = json.load(f)

                                creation_date = datetime.fromisoformat(manifest_data['creation_date'])
                                if creation_date < cutoff_date:
                                    shutil.rmtree(quarantine_dir)
                                    purged_count += 1
                                    self.logger.info(f"Purged old quarantine: {quarantine_dir.name}")

                            except Exception as e:
                                self.logger.warning(f"Failed to process quarantine {quarantine_dir}: {e}")

                    pbar.update(1)
                    pbar.set_postfix({'Purged': purged_count})

        if purged_count > 0:
            self.logger.info(f"Auto-purged {purged_count} old quarantine sessions")


# ====================================================================================================
# COMPLETE v5 ULTIMATE ENHANCED CHESS SEMANTIC ANALYZER - ENHANCED WITH IDF WEIGHTING
# ====================================================================================================

@dataclass
class PGNAnalysisResult:
    """Results from hybrid PGN analysis with EVS scoring"""
    evs_score: float  # Educational Value Score 0-100
    structure_score: float  # 0-20
    annotation_richness: float  # 0-20
    humanness_score: float  # 0-20
    educational_context: float  # 0-15
    game_type: str  # annotated_game, complete_game, position_study, database_dump
    total_moves: int
    annotation_density: float
    has_headers: bool
    has_variations: bool
    famous_game_detected: bool
    educational_cues: List[str]


@dataclass
class SemanticAnalysisResult:
    """Results from semantic analysis with v5 PGN integration and IDF weighting"""
    content_quality_score: float
    chess_domain_relevance: float
    instructional_value: float
    concept_density: float
    explanation_clarity: float
    top_concepts: List[str]
    semantic_categories: Dict[str, float]
    # Enhanced fields from v4
    publication_year_score: float
    comprehensive_concept_score: float
    detected_openings: List[str]
    detected_players: List[str]
    detected_books: List[str]
    # v5 PGN Integration
    pgn_analysis: PGNAnalysisResult
    pgn_integration_score: float


class AdvancedPGNDetector:
    """v5 Hybrid PGN detection combining simple + sophisticated approaches"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # Compiled regex patterns for performance
        self._compile_patterns()

        # Educational cue patterns
        self.educational_patterns = [
            r'(?i)\b(?:because|since|therefore|thus|consequently)\b',
            r'(?i)\b(?:idea|plan|strategy|concept|principle)\b',
            r'(?i)\b(?:better|stronger|weaker|good|bad|excellent|poor)\s+(?:move|position|choice)\b',
            r'(?i)\b(?:white|black)\s+(?:should|must|needs to|has to|wants to|aims to)\b',
            r'(?i)\b(?:typical|common|standard|usual|normal)\s+(?:position|move|structure)\b',
            r'(?i)\b(?:advantage|disadvantage|edge|initiative|pressure)\b',
            r'(?i)\b(?:attacking|defending|controlling|improving|developing)\b'
        ]

        # Famous game detection patterns
        self.famous_contexts = [
            r'(?i)\b(?:world championship|candidates|olympiad)\b',
            r'(?i)\b(?:kasparov|karpov|fischer|carlsen|anand|kramnik|tal|petrosian|spassky|botvinnik)\b',
            r'(?i)\b(?:immortal game|evergreen game|opera game|game of the century)\b'
        ]

    def _compile_patterns(self):
        """Compile regex patterns for performance"""
        self.move_pattern = re.compile(r'\b(?:[KQRBN]?[a-h]?[1-8]?[x]?[a-h][1-8](?:=[QRBN])?[+#]?|O-O(?:-O)?[+#]?)\b')
        self.move_number_pattern = re.compile(r'\b\d+\.(?:\.\.)?\s*')
        self.annotation_pattern = re.compile(r'[!?]{1,2}')
        self.nag_pattern = re.compile(r'\$\d+')
        self.comment_pattern = re.compile(r'\{([^}]*)\}')
        self.variation_pattern = re.compile(r'\(([^)]*)\)')
        self.header_pattern = re.compile(r'\[(\w+)\s+"([^"]*)"\]')
        self.result_pattern = re.compile(r'\b(?:1-0|0-1|1/2-1/2|\*)\b')

    def preprocess_text(self, text: str) -> str:
        """Enhanced text preprocessing for PDF artifacts and unicode"""
        if not text:
            return ""

        # Handle unicode and smart quotes
        text = text.replace('"', '"').replace('"', '"')
        text = text.replace(''', "'").replace(''', "'")

        # Fix PDF artifacts
        text = re.sub(r'([a-zA-Z])\s+([a-zA-Z])', r'\1\2', text)  # Fix broken words
        text = re.sub(r'\s+', ' ', text)  # Normalize whitespace

        # Fix broken move notation
        text = re.sub(r'(\d+)\s*\.\s*([KQRBN]?[a-h][1-8])', r'\1.\2', text)

        return text.strip()

    def detect_pgn_regions(self, text: str, window_size: int = 200) -> List[Tuple[str, int, int]]:
        """Detect PGN regions using sliding window approach"""
        text = self.preprocess_text(text)
        regions = []

        # Sliding window to find PGN-dense areas
        words = text.split()
        for i in range(0, len(words) - window_size + 1, window_size // 2):
            window_text = ' '.join(words[i:i + window_size])

            # Count chess indicators
            moves = len(self.move_pattern.findall(window_text))
            move_numbers = len(self.move_number_pattern.findall(window_text))

            # Threshold for PGN content (Grok's simple approach influence)
            if moves >= 10 and move_numbers >= 5:
                start_pos = len(' '.join(words[:i]))
                end_pos = len(' '.join(words[:i + window_size]))
                regions.append((window_text, start_pos, end_pos))

        return regions

    def analyze_structure(self, text: str) -> float:
        """Analyze PGN structure (0-20 points)"""
        score = 0.0

        # Check for headers (0-8 points)
        headers = self.header_pattern.findall(text)
        header_score = min(len(headers) * 1.5, 8.0)
        score += header_score

        # Check for proper move notation (0-6 points)
        moves = self.move_pattern.findall(text)
        move_numbers = self.move_number_pattern.findall(text)

        if moves and move_numbers:
            move_ratio = len(move_numbers) / len(moves) if moves else 0
            move_score = min(move_ratio * 6, 6.0)
            score += move_score

        # Check for game result (0-3 points)
        if self.result_pattern.search(text):
            score += 3.0

        # Check for complete game structure (0-3 bonus)
        if headers and moves and self.result_pattern.search(text):
            score += 3.0

        return min(score, 20.0)

    def analyze_annotation_richness(self, text: str) -> Tuple[float, float]:
        """Analyze annotation richness using hybrid approach (0-20 points)"""
        # Grok's simple approach: count annotations per move
        moves = self.move_pattern.findall(text)
        annotations = self.annotation_pattern.findall(text)

        annotation_density = 0.0
        if moves:
            annotation_density = len(annotations) / len(moves)

        score = 0.0

        # Base score from annotation density (Grok's 0.2 threshold)
        if annotation_density >= 0.2:
            score += min(annotation_density * 15, 10.0)

        # Comments and variations (ChatGPT's sophisticated approach)
        comments = self.comment_pattern.findall(text)
        variations = self.variation_pattern.findall(text)
        nags = self.nag_pattern.findall(text)

        # Comment quality scoring
        comment_score = 0.0
        for comment in comments:
            if len(comment) > 20:  # Substantive comments
                comment_score += 1.5
            elif len(comment) > 5:
                comment_score += 0.5

        # Variation scoring (Grok's simple depth approach)
        variation_score = 0.0
        for variation in variations:
            depth = variation.count('(') + 1
            variation_score += min(1 + depth * 0.5, 3.0)

        # Add component scores
        score += min(comment_score, 6.0)
        score += min(variation_score, 4.0)
        score += min(len(nags) * 0.5, 2.0)

        return min(score, 20.0), annotation_density

    def analyze_humanness(self, text: str) -> float:
        """Detect human vs engine analysis (0-20 points)"""
        score = 0.0

        # Educational language patterns (positive indicators)
        educational_matches = 0
        for pattern in self.educational_patterns:
            educational_matches += len(re.findall(pattern, text))

        score += min(educational_matches * 0.8, 12.0)

        # Engine noise detection (penalties)
        engine_indicators = [
            r'\b\d+\.\d{2}\b',  # Numerical evaluations
            r'\bcp\s*[-+]?\d+\b',  # Centipawn notation
            r'\b(?:depth|nodes|nps|time)\s*\d+\b'  # Engine statistics
        ]

        engine_noise = 0
        for pattern in engine_indicators:
            engine_noise += len(re.findall(pattern, text, re.IGNORECASE))

        penalty = min(engine_noise * 1.0, 8.0)
        score = max(score - penalty, 0.0)

        # Bonus for natural language flow
        sentence_count = text.count('.') + text.count('!') + text.count('?')
        if sentence_count > 0:
            avg_sentence_length = len(text.split()) / sentence_count
            if 8 <= avg_sentence_length <= 25:  # Natural range
                score += 3.0

        return min(score, 20.0)

    def analyze_educational_context(self, text: str, surrounding_text: str = "") -> Tuple[float, List[str]]:
        """Analyze educational context from surrounding text (0-15 points)"""
        score = 0.0
        educational_cues = []

        # Combine text sources
        full_text = text + " " + surrounding_text

        # Famous game detection
        famous_detected = False
        for pattern in self.famous_contexts:
            if re.search(pattern, full_text):
                famous_detected = True
                score += 3.0
                educational_cues.append("famous_game_context")
                break

        # Instructional context indicators
        instructional_indicators = [
            (r'(?i)\b(?:lesson|tutorial|example|demonstration)\b', "instructional_content"),
            (r'(?i)\b(?:analysis|annotation|commentary|explanation)\b', "analytical_content"),
            (r'(?i)\b(?:opening|middlegame|endgame)\s+(?:study|theory|guide)\b', "phase_specific_study"),
            (r'(?i)\b(?:master|grandmaster|world champion)\b', "expert_level_content"),
            (r'(?i)\b(?:diagram|position|move)\s+\d+\b', "structured_presentation")
        ]

        for pattern, cue_type in instructional_indicators:
            if re.search(pattern, full_text):
                score += 2.0
                educational_cues.append(cue_type)

        # Book/article context
        if any(indicator in full_text.lower() for indicator in
               ['chapter', 'page', 'author', 'published', 'edition']):
            score += 2.0
            educational_cues.append("published_content")

        return min(score, 15.0), educational_cues

    def classify_game_type(self, structure_score: float, annotation_richness: float,
                           humanness_score: float, educational_context: float) -> str:
        """Classify the type of PGN content"""

        if annotation_richness >= 12 and humanness_score >= 10:
            return "annotated_game"
        elif structure_score >= 15 and educational_context >= 8:
            return "complete_game"
        elif humanness_score >= 12 and educational_context >= 5:
            return "position_study"
        else:
            return "database_dump"

    def analyze_pgn_content(self, text: str, surrounding_text: str = "") -> PGNAnalysisResult:
        """Complete hybrid PGN analysis with EVS scoring"""
        if not text:
            return self._empty_pgn_result()

        try:
            # Preprocess text
            processed_text = self.preprocess_text(text)

            # Core analysis components
            structure_score = self.analyze_structure(processed_text)
            annotation_richness, annotation_density = self.analyze_annotation_richness(processed_text)
            humanness_score = self.analyze_humanness(processed_text)
            educational_context, educational_cues = self.analyze_educational_context(
                processed_text, surrounding_text
            )

            # Calculate EVS (0-100)
            evs_score = structure_score + annotation_richness + humanness_score + educational_context + 25  # Base 25 for valid PGN
            evs_score = min(evs_score, 100.0)

            # Additional metrics
            moves = self.move_pattern.findall(processed_text)
            total_moves = len(moves)
            has_headers = bool(self.header_pattern.search(processed_text))
            has_variations = bool(self.variation_pattern.search(processed_text))

            # Famous game detection
            famous_game_detected = any(re.search(pattern, text + " " + surrounding_text)
                                       for pattern in self.famous_contexts)

            # Game type classification
            game_type = self.classify_game_type(
                structure_score, annotation_richness, humanness_score, educational_context
            )

            return PGNAnalysisResult(
                evs_score=evs_score,
                structure_score=structure_score,
                annotation_richness=annotation_richness,
                humanness_score=humanness_score,
                educational_context=educational_context,
                game_type=game_type,
                total_moves=total_moves,
                annotation_density=annotation_density,
                has_headers=has_headers,
                has_variations=has_variations,
                famous_game_detected=famous_game_detected,
                educational_cues=educational_cues
            )

        except Exception as e:
            self.logger.error(f"PGN analysis failed: {e}")
            return self._empty_pgn_result()

    def _empty_pgn_result(self) -> PGNAnalysisResult:
        """Return empty PGN analysis result"""
        return PGNAnalysisResult(
            evs_score=0.0,
            structure_score=0.0,
            annotation_richness=0.0,
            humanness_score=0.0,
            educational_context=0.0,
            game_type="no_pgn_content",
            total_moves=0,
            annotation_density=0.0,
            has_headers=False,
            has_variations=False,
            famous_game_detected=False,
            educational_cues=[]
        )


class ChessSemanticAnalyzer:
    """Ultimate enhanced chess semantic analyzer v5.1 with comprehensive vocabulary, PGN integration, and IDF weighting"""

    def __init__(self, model_name: str = "all-MiniLM-L6-v2", device: str = "auto"):
        self.logger = logging.getLogger(__name__)
        self.device = self._setup_device(device)

        # Initialize models only if NLP libraries available
        if NLP_AVAILABLE:
            self.logger.info("Loading semantic models...")
            self.sentence_model = SentenceTransformer(model_name, device=self.device)
        else:
            self.sentence_model = None
            self.logger.warning("NLP libraries not available - using fallback analysis")

        # Initialize v5 hybrid PGN detector
        self.pgn_detector = AdvancedPGNDetector()

        # Enhanced chess vocabulary with curated books and openings
        self.chess_concepts = self._load_comprehensive_chess_concepts()
        self.chess_concept_embeddings = None

        # Initialize models lazily
        self._bert_model = None
        self._bert_tokenizer = None

        # IDF Enhancement - v5.1 NEW FEATURE
        self.idf_calculator = IDFCalculator()
        self.idf_weights: Optional[IDFWeights] = None
        self.idf_weights_path = "chess_idf_weights.json"
        self._load_existing_idf_weights()

        # Count total terms for reporting
        total_terms = sum(len(terms) for terms in self.chess_concepts.values())
        self.logger.info(f"Ultimate semantic analyzer v5.1 initialized with {total_terms} chess terms")

    def _setup_device(self, device: str) -> str:
        """Setup computation device"""
        if not NLP_AVAILABLE:
            return "cpu"

        if device == "auto":
            if torch.cuda.is_available():
                return "cuda"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                return "mps"  # Apple Silicon
            else:
                return "cpu"
        return device

    def _load_existing_idf_weights(self):
        """Load existing IDF weights if available - v5.1 NEW FEATURE"""
        self.idf_weights = self.idf_calculator.load_idf_weights(self.idf_weights_path)
        if self.idf_weights:
            self.logger.info("Using existing IDF weights for enhanced analysis")
        else:
            self.logger.info("No IDF weights found - will use uniform weighting until corpus analysis")

    def perform_corpus_idf_calculation(self, documents: List[str]):
        """Perform corpus-wide IDF calculation - v5.1 NEW FEATURE"""
        self.logger.info("Starting corpus-wide IDF calculation...")
        self.idf_weights = self.idf_calculator.calculate_corpus_idf(documents, self.chess_concepts)
        self.idf_calculator.save_idf_weights(self.idf_weights, self.idf_weights_path)
        self.logger.info("Corpus analysis complete - IDF-enhanced analysis now available")

    def _load_comprehensive_chess_concepts(self) -> Dict[str, List[str]]:
        """Load ultimate comprehensive chess concept dictionary with curated books and openings"""
        return {
            'basic_pieces_moves': [
                'pawn', 'rook', 'bishop', 'knight', 'queen', 'king', 'pieces',
                'move', 'moves', 'square', 'squares', 'board', 'position',
                'capture', 'captures', 'attack', 'attacks', 'defend', 'defense',
                'check', 'checkmate', 'stalemate', 'draw', 'resign',
                'white', 'black', 'player', 'opponent', 'game', 'chess',
                'material', 'advantage', 'winning', 'losing', 'equal'
            ],

            'chess_notation': [
                'algebraic notation', 'descriptive notation', 'pgn', 'fen',
                'san notation', 'long algebraic', 'coordinate notation',
                'figurine notation', 'move notation', 'score notation',
                'annotation', 'commentary', 'analysis', 'variation'
            ],

            'advanced_positional_concepts': [
                'pawn structure', 'space advantage', 'advanced pawn', 'bind', 'maroczy bind',
                'blockade', 'centralization', 'closed game', 'control of the center',
                'cramped position', 'doubled pawns', 'good bishop', 'bad bishop',
                'isolated pawn', 'backward pawn', 'passed pawn', 'connected passed pawns',
                'open file', 'pawn break', 'pawn chain', 'positional play', 'squeeze',
                'outpost', 'open files and ranks', 'weak squares', 'prophylaxis',
                'two weaknesses', 'restriction', 'neutralization', 'over-protection',
                'simplification', 'pawn breaks', 'coordination', 'development',
                'king safety', 'material gain', 'least active piece', 'maximum activity',
                'stability', 'trade', 'flexibility', 'attack principle', 'minimum force',
                'maximum force', 'sustained fighting', 'zugzwang', 'favorable pawn-structure',
                'initiative', 'piece activity', 'tension', 'exchanging pieces',
                'defending pieces', 'knight outposts', 'bishop pair advantage',
                'rook on open files', 'pawn majority', 'outside passed pawn',
                'hanging pawns', 'pawn islands', 'prophylactic thinking',
                'piece harmony', 'strategic breakthrough', 'central pawn duo'
            ],

            'instructional_vocabulary': [
                'dark-square bishop', 'dark squares', 'dead draw', 'dead position',
                'decoy', 'defense', 'deflection', 'demonstration board', 'descriptive notation',
                'desperado', 'development', 'diagonal', 'discovered attack', 'discovered check',
                'diversionary sacrifice', 'domination', 'double attack', 'double check',
                'doubled pawns', 'doubled rooks', 'double fianchetto', 'draw',
                'draw by insufficient material', 'draw by repetition', 'draw by stalemate',
                'drawish', 'duffer', 'dynamic play', 'eco', 'elo rating', 'en passant',
                'en prise', 'endgame', 'endgame study', 'engine', 'equalize', 'exchange',
                'exchange sacrifice', 'fianchetto', 'fifty-move rule', 'file',
                'fischerandom', 'fish', 'flag', 'flank', 'flank opening', 'fool\'s mate',
                'forced move', 'fork', 'fortress', 'gambit', 'grandmaster', 'half-open file',
                'hanging', 'hole', 'hypermodern', 'imbalance', 'initiative',
                'insufficient material', 'intermezzo', 'international master', 'isolated pawn',
                'kingside', 'knight', 'light-square bishop', 'light squares', 'liquidation',
                'long diagonal', 'loose', 'lost position', 'luft', 'major piece',
                'majority', 'mate', 'material', 'mating net', 'middlegame', 'minor piece',
                'minority attack', 'mobility', 'norm', 'notation', 'novelty', 'open file',
                'open game', 'opening', 'opposite-colored bishops', 'opposition', 'outpost',
                'outside passed pawn', 'overloading', 'passed pawn', 'passive', 'patzer',
                'pawn', 'pawn chain', 'pawn island', 'pawn storm', 'pawn structure',
                'perpetual check', 'piece', 'pin', 'poisoned pawn', 'positional play',
                'promotion', 'prophylaxis', 'protected passed pawn', 'queenside',
                'quiet move', 'rank', 'rapid chess', 'resign', 'rook', 'rook lift',
                'sacrifice', 'scholar\'s mate', 'sealed move', 'semi-open file',
                'skewer', 'smothered mate', 'space', 'stalemate', 'swindle', 'tabiya',
                'tactics', 'tempo', 'threefold repetition', 'time control', 'time pressure',
                'touch-move rule', 'transposition', 'triangulation', 'underpromotion',
                'weak square', 'windmill', 'wrong rook pawn', 'x-ray', 'zugzwang', 'zwickmuhle',
                'absolute seventh rank', 'adjournment', 'artificial castling', 'breakthrough',
                'central break', 'endgame transition', 'favorable imbalance', 'hanging pawns',
                'hypermodernism', 'key square', 'pawn duo', 'piece sacrifice for initiative',
                'prophylactic move', 'rule of the square', 'strategic plan', 'tempo gain',
                'weak color complex'
            ],

            'tactical_concepts': [
                'pin', 'fork', 'skewer', 'discovered attack', 'double attack',
                'deflection', 'decoy', 'clearance', 'interference', 'removing defender',
                'sacrifice', 'combination', 'tactical motif', 'tactical pattern',
                'knight fork', 'family fork', 'royal fork', 'bishop pin', 'rook pin',
                'absolute pin', 'relative pin', 'cross pin', 'counter pin',
                'back rank mate', 'smothered mate', 'epaulette mate', 'corridor mate',
                'discovered check', 'double check', 'windmill', 'zwischenzug',
                'in-between move', 'intermediate move', 'greek gift', 'sacrifice on h7',
                'clearance sacrifice', 'deflection sacrifice', 'attraction',
                'magnet', 'x-ray attack', 'battery', 'desperado', 'zugzwang',
                'remove the guard', 'destroy the defender', 'overload',
                'diversion', 'lure', 'mating net', 'mating attack', 'knight sacrifice',
                'bishop sacrifice', 'rook sacrifice', 'queen sacrifice', 'exchange sacrifice',
                'positional sacrifice', 'temporary sacrifice', 'sound sacrifice',
                'speculative sacrifice', 'intuitive sacrifice'
            ],

            'strategic_concepts': [
                'planning', 'strategy', 'evaluation', 'assessment', 'imbalance',
                'prophylaxis', 'prevention', 'weak point', 'strong point',
                'long-term advantage', 'positional sacrifice', 'strategic theme',
                'maneuvering', 'regrouping', 'piece coordination', 'harmony',
                'blockade', 'restriction', 'restraint', 'bind', 'squeeze',
                'breakthrough', 'pawn breakthrough', 'piece breakthrough',
                'tempo', 'tempi', 'time', 'development advantage',
                'piece development', 'rapid development', 'lagging development',
                'dynamic', 'static', 'permanent weakness', 'temporary weakness',
                'strategic planning', 'long-term thinking', 'positional understanding'
            ],

            'opening_principles': [
                'opening principles', 'development', 'center control',
                'central control', 'king safety', 'opening preparation',
                'opening repertoire', 'opening theory', 'book moves',
                'theoretical moves', 'novelty', 'new move', 'improvement',
                'gambit', 'sacrifice', 'pawn sacrifice', 'piece sacrifice',
                'initiative', 'development lead', 'time advantage', 'castle early',
                'rapid development', 'piece activity', 'central occupation'
            ],

            'curated_openings': [
                # 1.e4 Openings - Refined List (~75 entries)
                'ruy lopez closed', 'ruy lopez chigorin', 'ruy lopez breyer', 'ruy lopez zaitsev',
                'ruy lopez karpov', 'ruy lopez smyslov', 'ruy lopez marshall attack',
                'ruy lopez anti-marshall', 'ruy lopez berlin defense', 'ruy lopez berlin endgame',
                'ruy lopez open variation', 'ruy lopez exchange variation', 'ruy lopez steinitz defense',
                'ruy lopez schliemann gambit', 'ruy lopez arkhangelsk variation', 'ruy lopez classical defense',

                'sicilian najdorf', 'sicilian najdorf bg5', 'sicilian najdorf be3 english attack',
                'sicilian najdorf be2', 'sicilian najdorf f4', 'sicilian najdorf poisoned pawn',
                'sicilian dragon', 'sicilian dragon yugoslav attack', 'sicilian dragon classical',
                'sicilian dragon positional', 'sicilian accelerated dragon', 'sicilian accelerated dragon maroczy bind',
                'sicilian sveshnikov', 'sicilian scheveningen', 'sicilian scheveningen keres attack',
                'sicilian scheveningen english attack', 'sicilian taimanov', 'sicilian kan',
                'sicilian four knights', 'sicilian classical richter-rauzer', 'sicilian classical sozin',
                'sicilian kalashnikov', 'sicilian closed', 'sicilian grand prix attack',
                'sicilian alapin', 'sicilian rossolimo', 'sicilian moscow variation',

                'french winawer', 'french winawer poisoned pawn', 'french winawer armenian',
                'french classical', 'french classical steinitz', 'french classical maccutcheon',
                'french tarrasch', 'french tarrasch open', 'french tarrasch closed',
                'french advance', 'french advance milner-barry', 'french advance short system',
                'french exchange', 'french rubinstein',

                'caro-kann classical', 'caro-kann advance', 'caro-kann panov-botvinnik attack',
                'caro-kann two knights', 'caro-kann exchange', 'caro-kann fantasy variation',

                'italian game classical', 'italian game modern', 'evans gambit',
                'two knights defense fried liver attack', 'two knights defense traxler counter-attack',
                'two knights defense modern defense',

                'alekhine defense', 'alekhine defense four pawns attack', 'alekhine defense exchange',
                'alekhine defense modern', 'scandinavian defense', 'scandinavian defense qxd5',
                'scandinavian defense nf6', 'scandinavian defense portuguese',
                'pirc defense', 'pirc defense austrian attack', 'pirc defense classical',
                'pirc defense 150 attack', 'modern defense', 'philidor defense',
                'petroff defense', 'petroff defense classical', 'petroff defense modern attack',

                'vienna game', 'vienna gambit', 'king\'s gambit', 'king\'s gambit accepted',
                'king\'s gambit declined', 'falkbeer counter-gambit', 'bishop\'s opening',
                'scotch game', 'scotch game classical', 'scotch gambit',
                'four knights game', 'ponziani opening', 'center game', 'danish gambit',

                # 1.d4 Openings - Refined List (~100 entries)
                'queen\'s gambit declined', 'qgd orthodox', 'qgd lasker defense',
                'qgd tartakower-makogonov-bondarevsky', 'qgd cambridge springs', 'qgd exchange variation',
                'queen\'s gambit accepted', 'qga classical', 'qga central variation',

                'slav defense', 'slav defense classical', 'slav defense exchange',
                'slav defense chebanenko', 'semi-slav', 'semi-slav botvinnik system',
                'semi-slav anti-moscow gambit', 'semi-slav meran', 'semi-slav noteboom',

                'nimzo-indian', 'nimzo-indian rubinstein', 'nimzo-indian classical',
                'nimzo-indian samisch', 'nimzo-indian leningrad', 'queen\'s indian',
                'queen\'s indian fianchetto', 'queen\'s indian petrosian', 'queen\'s indian kasparov',

                'king\'s indian', 'king\'s indian classical', 'king\'s indian mar del plata',
                'king\'s indian samisch', 'king\'s indian four pawns attack',
                'king\'s indian fianchetto', 'king\'s indian bayonet attack',

                'grunfeld defense', 'grunfeld exchange', 'grunfeld russian',
                'grunfeld fianchetto', 'grunfeld bf4',

                'modern benoni', 'czech benoni', 'benko gambit', 'benko gambit accepted',
                'benko gambit declined', 'old indian defense',

                'catalan opening', 'catalan open', 'catalan closed',

                'dutch defense', 'dutch leningrad', 'dutch stonewall', 'dutch classical',
                'dutch staunton gambit',

                'london system', 'torre attack', 'trompowsky attack', 'colle system',
                'veresov opening', 'jobava-prie system',

                'budapest gambit', 'albin counter-gambit', 'blackmar-diemer gambit',

                # Flank Openings - Refined List (~40 entries)
                'english opening', 'english symmetrical', 'english four knights',
                'english hedgehog', 'english botvinnik system', 'english anglo-grunfeld',
                'english anglo-queen\'s indian', 'english reversed sicilian',

                'reti opening', 'reti king\'s indian attack', 'king\'s indian attack',

                'bird\'s opening', 'bird\'s opening leningrad', 'bird\'s opening classical',
                'from\'s gambit',

                'larsen\'s opening', 'polish opening', 'sokolsky opening',

                # Rare but Important (~25 entries)
                'giuoco piano', 'hungarian defense', 'owen\'s defense', 'st. george defense',
                'nimzowitsch defense', 'rapport-jobava system', 'grand prix attack',
                'anti-berlin systems', 'modern exchange variations'
            ],

            'endgame_concepts': [
                'endgame', 'ending', 'endgame theory', 'theoretical ending',
                'practical endgame', 'opposition', 'distant opposition', 'direct opposition',
                'zugzwang', 'triangulation', 'trebuchet', 'breakthrough',
                'king activity', 'king centralization', 'active king', 'passive king',
                'pawn promotion', 'promotion', 'underpromotion', 'queening',
                'pawn endgame', 'king and pawn endgame', 'rook endgame', 'rook ending',
                'minor piece endgame', 'bishop endgame', 'knight endgame',
                'queen endgame', 'opposite colored bishops', 'same colored bishops',
                'good bishop vs bad bishop', 'rook vs minor piece', 'rook vs knight',
                'rook vs bishop', 'lucena position', 'philidor position', 'vancura position',
                'fortress', 'drawing technique', 'stalemate tricks', 'perpetual check',
                'fifty-move rule', 'theoretical draw', 'practical chances', 'endgame study',
                'tablebase', 'nalimov tablebase', 'syzygy tablebase', 'endgame database'
            ],

            'famous_players_classical': [
                'morphy', 'paul morphy', 'steinitz', 'wilhelm steinitz', 'lasker', 'emanuel lasker',
                'capablanca', 'jose capablanca', 'alekhine', 'alexander alekhine',
                'euwe', 'max euwe', 'botvinnik', 'mikhail botvinnik', 'smyslov', 'vasily smyslov',
                'tal', 'mikhail tal', 'petrosian', 'tigran petrosian', 'spassky', 'boris spassky',
                'fischer', 'bobby fischer', 'robert fischer', 'karpov', 'anatoly karpov',
                'kasparov', 'garry kasparov', 'kramnik', 'vladimir kramnik',
                'anand', 'viswanathan anand', 'carlsen', 'magnus carlsen', 'gukesh', 'dommaraju gukesh'
            ],

            'famous_players_historical': [
                'anderssen', 'adolf anderssen', 'murphy', 'zukertort', 'johannes zukertort',
                'chigorin', 'mikhail chigorin', 'tarrasch', 'siegbert tarrasch',
                'marshall', 'frank marshall', 'rubinstein', 'akiba rubinstein',
                'nimzowitsch', 'aaron nimzowitsch', 'reti', 'richard reti', 'breyer', 'gyula breyer',
                'bogolyubov', 'efim bogolyubov', 'spielmann', 'rudolf spielmann',
                'vidmar', 'milan vidmar', 'janowski', 'dawid janowski', 'schlechter', 'carl schlechter',
                'pillsbury', 'harry pillsbury', 'burn', 'amos burn', 'maroczy', 'geza maroczy',
                'duras', 'oldrich duras', 'teichmann', 'richard teichmann'
            ],

            'modern_players': [
                'caruana', 'fabiano caruana', 'ding liren', 'nepomniachtchi', 'ian nepomniachtchi',
                'nakamura', 'hikaru nakamura', 'aronian', 'levon aronian',
                'mamedyarov', 'shakhriyar mamedyarov', 'grischuk', 'alexander grischuk',
                'vachier-lagrave', 'maxime vachier-lagrave', 'so', 'wesley so',
                'giri', 'anish giri', 'radjabov', 'teimour radjabov', 'topalov', 'veselin topalov',
                'ivanchuk', 'vassily ivanchuk', 'shirov', 'alexei shirov', 'adams', 'michael adams',
                'short', 'nigel short', 'leko', 'peter leko', 'polgar', 'judit polgar',
                'susan polgar', 'sofia polgar', 'hou yifan', 'firouzja', 'alireza firouzja',
                'pragg', 'praggnanandhaa', 'abdusattorov', 'nodirbek abdusattorov',
                'erigaisi', 'arjun erigaisi', 'keymer', 'vincent keymer', 'duda', 'jan-krzysztof duda'
            ],

            'instructional_concepts': [
                'chess principle', 'chess rule', 'chess law', 'learning method',
                'training exercise', 'improvement technique', 'study plan',
                'chess understanding', 'pattern recognition', 'calculation',
                'visualization', 'analysis', 'annotation', 'commentary',
                'explanation', 'instruction', 'teaching', 'coaching',
                'chess lesson', 'chess course', 'chess tutorial',
                'blunder', 'mistake', 'inaccuracy', 'good move', 'excellent move',
                'brilliant move', 'best move', 'forced move', 'only move',
                'puzzle', 'exercise', 'drill', 'practice', 'study',
                'masterclass', 'lecture', 'demonstration', 'intermediate level',
                'advanced level', 'master level', 'expert level', 'professional level'
            ],

            'modern_chess_technology': [
                'engine evaluation', 'computer analysis', 'stockfish', 'komodo', 'leela chess zero',
                'alphazero', 'chess engine', 'analysis engine', 'centipawn', 'centipawn loss',
                'engine depth', 'nodes per second', 'tablebase', 'endgame tablebase',
                'opening book', 'engine opening book', 'neural network', 'machine learning',
                'artificial intelligence', 'computer chess', 'chess software', 'database',
                'megabase', 'chessbase', 'fritz', 'chess assistant', 'online chess',
                'chess.com', 'lichess', 'internet chess club', 'chess server'
            ],

            'tournament_concepts': [
                'world championship', 'world chess championship', 'candidates tournament', 'interzonal',
                'olympiad', 'chess olympiad', 'world cup', 'fide grand prix', 'grand prix',
                'candidates cycle', 'fide', 'world chess federation', 'rating', 'elo rating',
                'fide rating', 'title', 'grandmaster', 'gm', 'international master', 'im',
                'fide master', 'fm', 'candidate master', 'cm', 'chess master', 'master', 'expert',
                'tournament', 'championship', 'match', 'round robin', 'swiss system',
                'knockout', 'playoff', 'armageddon', 'tiebreak', 'rapid tiebreak'
            ],

            'time_controls': [
                'time control', 'clock', 'chess clock', 'digital clock', 'time pressure',
                'zeitnot', 'flag', 'increment', 'delay', 'fischer increment',
                'bronstein delay', 'rapid chess', 'blitz chess', 'bullet chess',
                'correspondence chess', 'postal chess', 'email chess',
                'classical time control', 'long time control', 'time trouble',
                'classical chess', 'standard time control', 'tournament time control'
            ],

            'chess_rules': [
                'castling', 'kingside castling', 'queenside castling', 'short castling', 'long castling',
                'en passant', 'en passant capture', 'promotion', 'pawn promotion',
                'fifty-move rule', 'threefold repetition', 'fivefold repetition',
                'insufficient material', 'dead position', 'illegal move',
                'touch-move rule', 'j\'adoube', 'adjust', 'draw offer', 'resignation',
                'arbiter', 'chief arbiter', 'rules', 'regulations', 'fide laws',
                'laws of chess', 'fide handbook'
            ],

            'chess_authors_theorists': [
                'dvoretsky', 'mark dvoretsky', 'aagaard', 'jacob aagaard', 'silman', 'jeremy silman',
                'watson', 'john watson', 'alburt', 'lev alburt', 'pachman', 'ludek pachman',
                'fine', 'reuben fine', 'euwe', 'max euwe', 'keres', 'paul keres',
                'bronstein', 'david bronstein', 'kotov', 'alexander kotov', 'averbach', 'yuri averbach',
                'smyslov', 'vasily smyslov', 'reshevsky', 'samuel reshevsky', 'najdorf', 'miguel najdorf',
                'geller', 'efim geller', 'polugaevsky', 'lev polugaevsky', 'spassky', 'boris spassky'
            ],

            'famous_chess_books': [
                # Classical Foundations
                'chess fundamentals', 'lasker\'s manual of chess', 'my system', 'chess praxis',
                'modern ideas in chess', 'judgment and planning in chess', 'pawn power in chess',
                'think like a grandmaster', 'the art of the middle game', 'the soviet chess primer',

                # Modern Positional/Strategic
                'secrets of modern chess strategy', 'modern chess strategy', 'simple chess',
                'chess strategy for club players', 'chess structures a grandmaster guide',
                'positional decision making in chess', 'dynamic decision making in chess',
                'technical decision making in chess', 'the seven deadly chess sins', 'chess for zebras',
                'techniques of positional play', 'evaluate like a grandmaster',
                'the road to chess improvement', 'pump up your rating', 'under the surface',
                'the complete manual of positional chess', 'how to play dynamic chess',
                'the method in chess',

                # Aagaard Series
                'grandmaster preparation calculation', 'grandmaster preparation positional play',
                'grandmaster preparation strategic play', 'grandmaster preparation attack defence',
                'grandmaster preparation endgame play', 'thinking inside the box',
                'excelling at chess', 'excelling at positional chess', 'excelling at technical chess',
                'excelling at combinational play', 'practical chess defence', 'applying logic in chess',

                # Advanced Training
                'winning chess middlegames', 'mastering chess middlegames', 'mastering chess strategy',
                'think like a super-gm', 'lessons with a grandmaster', 'analyzing the chess mind',
                'best play', 'invisible chess moves', 'calculate like a grandmaster',
                'the survival guide to competitive chess', 'how chess games are won and lost',
                'build up your chess', 'boost your chess', 'chess evolution', 'move first think later',
                'the inner game of chess', 'the amateur\'s mind',

                # Tactics & Attacking
                'the art of attack in chess', 'the art of sacrifice in chess',
                'attack with mikhail tal', 'forcing chess moves', 'the ultimate chess puzzle book',
                'chess tactics from scratch', 'predator at the chessboard', 'creative chess',
                '101 attacking ideas in chess', 'sacrifice and initiative in chess',

                # Endgames
                'dvoretsky\'s endgame manual', 'silman\'s complete endgame course',
                'fundamental chess endings', 'endgame strategy', 'secrets of pawnless endings',
                'secrets of rook endings', 'understanding chess endgames', 'rook endings',
                '100 endgames you must know', 'the survival guide to rook endings',
                'practical rook endings', 'chess endings essential knowledge', 'endgame challenge',
                'nunn\'s chess endings', 'secrets of pawn endings', 'practical chess endings',
                'essential chess endings for advanced players', 'practical endgame lessons',
                'secrets of queen endgames',

                # Opening Theory
                'fundamental chess openings', 'mastering the chess openings',
                'gm repertoire 1.d4', 'gm repertoire the grunfeld', 'gm repertoire the english opening',
                'kotronias on the king\'s indian', 'gm repertoire 1.e4 vs french caro-kann philidor',
                'gm repertoire 1.e4 vs the sicilian', 'gm repertoire the french defence',
                'gm repertoire the caro-kann', 'playing 1.d4 the queen\'s gambit',
                'playing 1.d4 the indian defences', 'playing 1.e4 caro-kann 1...e5 minor lines',
                'playing 1.e4 sicilian french', 'playing the grunfeld', 'the king\'s gambit',
                'the complete c3 sicilian', 'understanding the chess openings',

                # Game Collections & History
                'my 60 memorable games', 'zurich international chess tournament 1953',
                'the life and games of mikhail tal', 'my best games of chess', 'new york 1924',
                '100 selected games', 'my great predecessors', 'modern chess revolution in the 70s',
                'kasparov vs karpov', 'endgame virtuoso', 'the most instructive games of chess ever played',
                'fire on board', 'my life games', 'russian silhouettes', 'game changer',
                'paul morphy the pride and sorrow of chess', 'spassky\'s 100 best games',
                'bobby fischer rediscovered', 'why lasker matters',
                'tal petrosian spassky korchnoi', 'karpov\'s strategic wins',
                'emanuel lasker a chess biography', 'the games of tigran petrosian',
                'how i beat fischer\'s record', 'endgame fischer bio',

                # Modern Computer-Era
                'the silicon road to chess improvement', 'a guide to chess improvement',
                'secrets of practical chess', 'grandmaster chess move by move',
                'understanding chess move by move', 'a history of chess',
                'the oxford companion to chess'
            ]
        }

    def analyze_chess_content(self, text: str, year: str = "UnknownYear",
                              author: str = "", surrounding_text: str = "") -> SemanticAnalysisResult:
        """Enhanced v5.1 analysis with integrated PGN detection and IDF weighting"""
        if not text or len(text.strip()) < 50:
            return self._empty_result()

        try:
            # Traditional semantic analysis (from v4)
            chunks = self._chunk_text(text, max_length=512)

            domain_relevance = self._analyze_domain_relevance(chunks)
            instructional_value = self._analyze_instructional_value(chunks)
            concept_density = self._analyze_concept_density(chunks)
            explanation_clarity = self._analyze_explanation_clarity(chunks)
            top_concepts = self._extract_top_concepts(chunks)
            semantic_categories = self._categorize_semantic_content(chunks)

            publication_score = self.calculate_publication_year_score(year, author)
            comprehensive_score = self._comprehensive_concept_analysis(text)
            detected_openings = self._detect_openings(text)
            detected_players = self._detect_players(text)
            detected_books = self._detect_books(text)

            # v5 Enhanced PGN Analysis
            pgn_analysis = self.pgn_detector.analyze_pgn_content(text, surrounding_text)

            # v5 Integration Score - combines semantic + PGN analysis
            pgn_integration_score = self._calculate_pgn_integration_score(
                domain_relevance, instructional_value, concept_density, pgn_analysis
            )

            # Enhanced content quality with v5 integration
            content_quality = self._calculate_v5_content_quality(
                domain_relevance, instructional_value, concept_density,
                explanation_clarity, comprehensive_score, pgn_analysis
            )

            return SemanticAnalysisResult(
                content_quality_score=content_quality,
                chess_domain_relevance=domain_relevance,
                instructional_value=instructional_value,
                concept_density=concept_density,
                explanation_clarity=explanation_clarity,
                top_concepts=top_concepts,
                semantic_categories=semantic_categories,
                publication_year_score=publication_score,
                comprehensive_concept_score=comprehensive_score,
                detected_openings=detected_openings,
                detected_players=detected_players,
                detected_books=detected_books,
                pgn_analysis=pgn_analysis,
                pgn_integration_score=pgn_integration_score
            )

        except Exception as e:
            self.logger.error(f"v5.1 semantic analysis failed: {e}")
            return self._empty_result()

    def _calculate_pgn_integration_score(self, domain_relevance: float, instructional_value: float,
                                         concept_density: float, pgn_analysis: PGNAnalysisResult) -> float:
        """Calculate integrated score combining semantic analysis with PGN EVS"""

        # Normalize EVS score to 0-1 range
        evs_normalized = pgn_analysis.evs_score / 100.0

        # Weight factors based on content type
        if pgn_analysis.game_type == "annotated_game":
            # High-value annotated games get EVS priority
            weights = {'semantic': 0.3, 'evs': 0.7}
        elif pgn_analysis.game_type == "complete_game":
            # Balanced weighting for complete games
            weights = {'semantic': 0.5, 'evs': 0.5}
        elif pgn_analysis.game_type == "position_study":
            # Semantic analysis more important for studies
            weights = {'semantic': 0.7, 'evs': 0.3}
        else:  # database_dump or no_pgn_content
            # Semantic analysis dominates for non-PGN content
            weights = {'semantic': 0.9, 'evs': 0.1}

        # Calculate semantic component
        semantic_component = (domain_relevance + instructional_value + concept_density) / 3

        # Calculate integrated score
        integrated_score = (
                semantic_component * weights['semantic'] +
                evs_normalized * weights['evs']
        )

        # Bonus for high-quality combinations
        if evs_normalized > 0.7 and semantic_component > 0.7:
            integrated_score = min(integrated_score * 1.15, 1.0)

        return integrated_score

    def _calculate_v5_content_quality(self, domain_relevance: float, instructional_value: float,
                                      concept_density: float, explanation_clarity: float,
                                      comprehensive_score: float, pgn_analysis: PGNAnalysisResult) -> float:
        """Enhanced v5.1 content quality calculation with PGN integration"""

        # Base semantic quality (v4 approach)
        semantic_quality = (
                domain_relevance * 0.22 +
                instructional_value * 0.20 +
                concept_density * 0.22 +
                explanation_clarity * 0.16 +
                comprehensive_score * 0.20
        )

        # PGN quality component
        evs_normalized = pgn_analysis.evs_score / 100.0

        # Dynamic weighting based on PGN presence and quality
        if pgn_analysis.evs_score >= 70:
            # High-quality PGN content gets significant boost
            final_quality = semantic_quality * 0.6 + evs_normalized * 0.4
        elif pgn_analysis.evs_score >= 50:
            # Medium-quality PGN content
            final_quality = semantic_quality * 0.75 + evs_normalized * 0.25
        elif pgn_analysis.evs_score > 0:
            # Some PGN content present
            final_quality = semantic_quality * 0.85 + evs_normalized * 0.15
        else:
            # Pure semantic content (no PGN)
            final_quality = semantic_quality

        # Famous game bonus
        if pgn_analysis.famous_game_detected:
            final_quality = min(final_quality * 1.1, 1.0)

        return min(final_quality, 1.0)

    def calculate_publication_year_score(self, year: str, author: str = "") -> float:
        """Enhanced publication year score with sliding scale"""
        if year == "UnknownYear" or not year:
            return 0.0

        try:
            year_int = int(year)
        except (ValueError, TypeError):
            return 0.0

        # Enhanced sliding scale - rewards both classics and modern works
        if year_int <= 1960:  # Chess classics
            base_score = 12 + min(3, (1960 - year_int) / 20)  # Up to 15
        elif year_int >= 2020:  # Latest modern works
            base_score = 15
        elif year_int >= 2015:  # Recent modern works
            base_score = 14
        elif year_int >= 2010:
            base_score = 13
        elif year_int >= 2005:
            base_score = 12
        elif year_int >= 2000:
            base_score = 11
        elif year_int >= 1995:
            base_score = 10
        elif year_int >= 1985:
            base_score = 9
        else:  # 1961-1984
            base_score = 7

        # Enhanced author reputation bonus
        author_lower = author.lower() if author else ""

        # Trusted authors (get bonus points)
        famous_authors = [
            'kasparov', 'fischer', 'karpov', 'carlsen', 'anand', 'kramnik', 'shirov',
            'dvoretsky', 'aagaard', 'silman', 'watson', 'alburt', 'pachman', 'euwe',
            'fine', 'tal', 'petrosian', 'spassky', 'botvinnik', 'lasker', 'capablanca',
            'alekhine', 'bronstein', 'kotov', 'averbach', 'smyslov', 'reshevsky'
        ]

        # Excluded authors (explicitly no bonus)
        excluded_authors = [
            'cyrus lakdawala', 'lakdawala',
            'eric schiller', 'schiller',
            'raymond keene', 'keene',
            'fred reinfeld', 'reinfeld',
            'i.a. horowitz', 'horowitz'
        ]

        author_bonus = 0

        # Check exclusion list first
        is_excluded = any(excluded in author_lower for excluded in excluded_authors)

        if not is_excluded:
            for famous in famous_authors:
                if famous in author_lower:
                    author_bonus = 2
                    break

        return min(base_score + author_bonus, 15.0)

    def _get_bert_models(self):
        """Lazy load BERT models"""
        if not NLP_AVAILABLE:
            return None, None

        if self._bert_model is None:
            model_name = "distilbert-base-uncased"
            self._bert_tokenizer = AutoTokenizer.from_pretrained(model_name)
            self._bert_model = AutoModel.from_pretrained(model_name).to(self.device)
        return self._bert_model, self._bert_tokenizer

    def _chunk_text(self, text: str, max_length: int = 512) -> List[str]:
        """Break text into manageable chunks"""
        sentences = text.split('.')
        chunks = []
        current_chunk = ""

        for sentence in sentences:
            if len(current_chunk) + len(sentence) < max_length:
                current_chunk += sentence + "."
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + "."

        if current_chunk:
            chunks.append(current_chunk.strip())

        return chunks[:20]  # Limit to first 20 chunks for performance

    def _analyze_domain_relevance(self, chunks: List[str]) -> float:
        """Enhanced domain relevance analysis with optional IDF weighting - v5.1 ENHANCED"""
        if not chunks:
            return 0.0

        # Use IDF weighting if available, otherwise fall back to keyword analysis
        if self.idf_weights and NLP_AVAILABLE and self.sentence_model:
            return self._idf_weighted_domain_relevance(chunks)
        else:
            return self._keyword_domain_relevance_fallback(chunks)

    def _idf_weighted_domain_relevance(self, chunks: List[str]) -> float:
        """IDF-weighted domain relevance analysis - v5.1 NEW FEATURE"""
        text = " ".join(chunks).lower()
        total_weighted_score = 0.0
        total_possible_weight = 0.0

        # Category importance weights
        category_weights = {
            'advanced_positional_concepts': 4.0,
            'instructional_vocabulary': 3.5,
            'tactical_concepts': 3.5,
            'strategic_concepts': 3.5,
            'endgame_concepts': 3.0,
            'curated_openings': 2.5,
            'famous_chess_books': 2.5,
            'chess_authors_theorists': 2.0,
            'famous_players_classical': 2.0,
            'modern_players': 2.0,
            'instructional_concepts': 1.8,
            'tournament_concepts': 1.5,
            'modern_chess_technology': 1.5,
            'time_controls': 1.0,
            'chess_rules': 1.0,
            'basic_pieces_moves': 0.8
        }

        # Calculate IDF-weighted matches
        for category, terms in self.chess_concepts.items():
            category_weight = category_weights.get(category, 1.0)

            for term in terms:
                term_lower = term.lower()
                idf_weight = self.idf_weights.term_weights.get(term_lower, 1.0)

                # Combined weight: category importance * IDF weight
                combined_weight = category_weight * idf_weight
                total_possible_weight += combined_weight

                if term_lower in text:
                    total_weighted_score += combined_weight

        # Normalize by total possible weight
        if total_possible_weight > 0:
            relevance = total_weighted_score / total_possible_weight
        else:
            relevance = 0.0

        return min(relevance, 1.0)

    def _keyword_domain_relevance_fallback(self, chunks: List[str]) -> float:
        """Enhanced fallback with comprehensive vocabulary when IDF not available"""
        if not chunks:
            return 0.0

        text = " ".join(chunks).lower()
        total_words = len(text.split())

        if total_words == 0:
            return 0.0

        # Count matches across all categories with enhanced weighting
        total_weighted_matches = 0
        category_weights = {
            'advanced_positional_concepts': 4.0,
            'instructional_vocabulary': 3.0,
            'tactical_concepts': 3.0,
            'strategic_concepts': 3.0,
            'curated_openings': 2.5,
            'endgame_concepts': 2.5,
            'modern_chess_technology': 2.0,
            'chess_authors_theorists': 2.0,
            'famous_chess_books': 2.0,
            'famous_players_classical': 1.8,
            'modern_players': 1.8,
            'instructional_concepts': 1.5,
            'tournament_concepts': 1.2,
            'basic_pieces_moves': 1.0
        }

        for category, terms in self.chess_concepts.items():
            weight = category_weights.get(category, 1.0)
            for term in terms:
                if term.lower() in text:
                    total_weighted_matches += weight

        # Normalize by text length
        relevance_score = min(total_weighted_matches / max(total_words / 50, 1), 1.0)
        return relevance_score

    def _analyze_instructional_value(self, chunks: List[str]) -> float:
        """Enhanced instructional value analysis"""
        instructional_indicators = [
            'understand', 'explain', 'demonstrate', 'analyze', 'evaluate',
            'example', 'exercise', 'practice', 'study', 'improve', 'master',
            'technique', 'method', 'approach', 'principle', 'strategy', 'concept',
            'how to', 'what is', 'why does', 'when should', 'remember',
            'important', 'key', 'essential', 'fundamental', 'critical',
            'lesson', 'tutorial', 'guide', 'instruction', 'advanced', 'intermediate',
            'master level', 'expert level', 'professional', 'theoretical',
            'practical application', 'deep understanding', 'comprehensive'
        ]

        beginner_penalties = [
            'beginner', 'basic', 'simple', 'easy', 'elementary', 'first steps',
            'learn to play', 'how pieces move', 'chess for kids'
        ]

        total_score = 0.0
        for chunk in chunks:
            chunk_lower = chunk.lower()

            keyword_score = sum(1 for word in instructional_indicators if word in chunk_lower)
            penalty = sum(2 for term in beginner_penalties if term in chunk_lower)

            advanced_patterns = ['advanced technique', 'master class', 'theoretical foundation', 'deep analysis']
            advanced_score = sum(3 for pattern in advanced_patterns if pattern in chunk_lower)

            question_patterns = ['how to', 'what is', 'why does', 'when should']
            question_score = sum(2 for pattern in question_patterns if pattern in chunk_lower)

            explanation_patterns = ['because', 'therefore', 'this means', 'the reason', 'consequently']
            explanation_score = sum(1 for pattern in explanation_patterns if pattern in chunk_lower)

            chunk_score = (keyword_score + question_score + explanation_score + advanced_score - penalty) / len(
                chunk.split())
            total_score += max(min(chunk_score, 0.15), 0.0)

        return min(total_score / len(chunks), 1.0) if chunks else 0.0

    def _analyze_concept_density(self, chunks: List[str]) -> float:
        """Enhanced concept density with comprehensive vocabulary"""
        if not chunks:
            return 0.0

        text = " ".join(chunks).lower()
        total_words = len(text.split())

        if total_words == 0:
            return 0.0

        weighted_concepts = 0
        category_weights = {
            'advanced_positional_concepts': 4.0,
            'instructional_vocabulary': 3.0,
            'tactical_concepts': 3.0,
            'strategic_concepts': 3.0,
            'endgame_concepts': 2.5,
            'curated_openings': 2.0,
            'modern_chess_technology': 2.0,
            'chess_authors_theorists': 2.0,
            'famous_chess_books': 2.0,
            'famous_players_classical': 1.8,
            'modern_players': 1.8,
            'instructional_concepts': 1.5,
            'tournament_concepts': 1.2,
            'time_controls': 1.0,
            'chess_rules': 1.0,
            'basic_pieces_moves': 0.8
        }

        for category, concepts in self.chess_concepts.items():
            weight = category_weights.get(category, 1.0)
            for concept in concepts:
                if concept.lower() in text:
                    weighted_concepts += weight

        density = weighted_concepts / (total_words / 100)
        return min(density / 30, 1.0)  # Adjusted scale

    def _comprehensive_concept_analysis(self, text: str) -> float:
        """Enhanced comprehensive analysis"""
        text_lower = text.lower()

        coverage_scores = {}
        importance_weights = {
            'advanced_positional_concepts': 4.0,
            'instructional_vocabulary': 3.0,
            'tactical_concepts': 3.0,
            'strategic_concepts': 3.0,
            'endgame_concepts': 2.5,
            'curated_openings': 2.0,
            'modern_chess_technology': 2.0,
            'chess_authors_theorists': 2.0,
            'famous_chess_books': 2.0,
            'famous_players_classical': 1.5,
            'modern_players': 1.5,
            'instructional_concepts': 1.2,
            'tournament_concepts': 1.0,
            'basic_pieces_moves': 0.8
        }

        for category, terms in self.chess_concepts.items():
            matches = sum(1 for term in terms if term.lower() in text_lower)
            category_size = len(terms)
            coverage = min(matches / max(category_size * 0.08, 1), 1.0)
            coverage_scores[category] = coverage

        weighted_score = 0
        total_weight = 0
        for category, score in coverage_scores.items():
            weight = importance_weights.get(category, 1.0)
            weighted_score += score * weight
            total_weight += weight

        return weighted_score / total_weight if total_weight > 0 else 0.0

    def _detect_openings(self, text: str) -> List[str]:
        """Enhanced opening detection with curated list"""
        text_lower = text.lower()
        detected = []

        for opening in self.chess_concepts.get('curated_openings', []):
            if opening.lower() in text_lower:
                detected.append(opening)

        return detected[:20]  # Increased limit

    def _detect_players(self, text: str) -> List[str]:
        """Enhanced player detection"""
        text_lower = text.lower()
        detected = []

        player_categories = ['famous_players_classical', 'famous_players_historical', 'modern_players']
        for category in player_categories:
            for player in self.chess_concepts.get(category, []):
                if player.lower() in text_lower:
                    detected.append(player)

        return detected[:20]  # Increased limit

    def _detect_books(self, text: str) -> List[str]:
        """Detect famous chess books mentioned in text"""
        text_lower = text.lower()
        detected = []

        for book in self.chess_concepts.get('famous_chess_books', []):
            if book.lower() in text_lower:
                detected.append(book)

        return detected[:15]  # Limit for performance

    def _analyze_explanation_clarity(self, chunks: List[str]) -> float:
        """Enhanced explanation clarity analysis"""
        clarity_indicators = {
            'structure': ['first', 'second', 'third', 'finally', 'then', 'next', 'subsequently'],
            'clarity': ['clear', 'obvious', 'straightforward', 'evident', 'apparent'],
            'examples': ['for example', 'such as', 'like', 'consider', 'imagine', 'instance'],
            'transitions': ['however', 'therefore', 'meanwhile', 'consequently', 'furthermore'],
            'emphasis': ['important', 'crucial', 'key', 'essential', 'critical', 'vital'],
            'explanation': ['because', 'since', 'due to', 'as a result', 'this means']
        }

        total_score = 0.0
        for chunk in chunks:
            chunk_lower = chunk.lower()
            chunk_score = 0.0

            for category, indicators in clarity_indicators.items():
                category_score = sum(1 for indicator in indicators if indicator in chunk_lower)
                weight = 0.15 if category in ['examples', 'explanation'] else 0.1
                chunk_score += category_score * weight

            # Penalty for overly complex sentences
            avg_sentence_length = len(chunk.split()) / max(chunk.count('.'), 1)
            if avg_sentence_length > 30:
                chunk_score *= 0.7
            elif avg_sentence_length > 25:
                chunk_score *= 0.85

            # Bonus for intermediate complexity
            if 15 <= avg_sentence_length <= 25:
                chunk_score *= 1.1

            total_score += min(chunk_score, 0.4)

        return min(total_score / len(chunks), 1.0) if chunks else 0.0

    def _extract_top_concepts(self, chunks: List[str]) -> List[str]:
        """Enhanced concept extraction with comprehensive vocabulary"""
        text = " ".join(chunks).lower()
        concept_counts = {}

        category_weights = {
            'advanced_positional_concepts': 3.0,
            'instructional_vocabulary': 2.5,
            'tactical_concepts': 2.5,
            'strategic_concepts': 2.5,
            'endgame_concepts': 2.0,
            'curated_openings': 2.0,
            'modern_chess_technology': 1.8,
            'chess_authors_theorists': 1.8,
            'famous_chess_books': 1.8
        }

        for category, concepts in self.chess_concepts.items():
            weight = category_weights.get(category, 1.0)
            for concept in concepts:
                if concept.lower() in text:
                    weighted_count = (concept_counts.get(concept, 0) + 1) * weight
                    concept_counts[concept] = weighted_count

        sorted_concepts = sorted(concept_counts.items(), key=lambda x: x[1], reverse=True)
        return [concept for concept, count in sorted_concepts[:25]]

    def _categorize_semantic_content(self, chunks: List[str]) -> Dict[str, float]:
        """Enhanced semantic categorization"""
        if not chunks:
            return {}

        text = " ".join(chunks)
        total_words = len(text.split())

        category_scores = {}
        for category, concepts in self.chess_concepts.items():
            matches = sum(1 for concept in concepts if concept.lower() in text.lower())
            score = matches / max(total_words / 200, 1) if total_words > 0 else 0
            category_scores[category] = min(score, 1.0)

        return category_scores

    def _empty_result(self) -> SemanticAnalysisResult:
        """Return empty result for failed analysis"""
        return SemanticAnalysisResult(
            content_quality_score=0.0,
            chess_domain_relevance=0.0,
            instructional_value=0.0,
            concept_density=0.0,
            explanation_clarity=0.0,
            top_concepts=[],
            semantic_categories={},
            publication_year_score=0.0,
            comprehensive_concept_score=0.0,
            detected_openings=[],
            detected_players=[],
            detected_books=[],
            pgn_analysis=self.pgn_detector._empty_pgn_result(),
            pgn_integration_score=0.0
        )


class RAGFitnessEvaluator:
    """Enhanced RAG fitness evaluator with v5 PGN content integration"""

    def __init__(self, semantic_analyzer: ChessSemanticAnalyzer):
        self.semantic_analyzer = semantic_analyzer
        self.logger = logging.getLogger(__name__)

    def evaluate_rag_fitness(self, text: str, title: str = "",
                             semantic_result: Optional[SemanticAnalysisResult] = None) -> Dict[str, Any]:
        """Comprehensive RAG fitness evaluation with v5 PGN integration"""
        if not text:
            return self._empty_fitness_result()

        try:
            if semantic_result is None:
                semantic_result = self.semantic_analyzer.analyze_chess_content(text)

            chunkability = self._evaluate_chunkability(text)
            answerability = self._evaluate_answerability(text, title)
            factual_density = self._evaluate_factual_density(text, semantic_result)
            retrieval_friendliness = self._evaluate_retrieval_friendliness(text)

            # v5 PGN Integration Bonus
            pgn_bonus = self._calculate_pgn_rag_bonus(semantic_result.pgn_analysis)
            factual_density = min(factual_density + pgn_bonus, 1.0)

            overall_score = self._calculate_overall_fitness(
                chunkability, answerability, factual_density, retrieval_friendliness
            )

            return {
                'overall_rag_fitness': overall_score,
                'chunkability_score': chunkability,
                'answerability_score': answerability,
                'factual_density_score': factual_density,
                'retrieval_friendliness_score': retrieval_friendliness,
                'pgn_detection_bonus': pgn_bonus,
                'evs_score': semantic_result.pgn_analysis.evs_score,
                'pgn_game_type': semantic_result.pgn_analysis.game_type,
                'fitness_reasoning': self._generate_fitness_reasoning(
                    chunkability, answerability, factual_density, retrieval_friendliness,
                    pgn_bonus, semantic_result.pgn_analysis
                )
            }

        except Exception as e:
            self.logger.error(f"RAG fitness evaluation failed: {e}")
            return self._empty_fitness_result()

    def _calculate_pgn_rag_bonus(self, pgn_analysis: PGNAnalysisResult) -> float:
        """Calculate PGN-specific RAG fitness bonus"""
        if pgn_analysis.evs_score == 0:
            return 0.0

        # Base bonus from EVS score
        base_bonus = min(pgn_analysis.evs_score / 500, 0.2)  # Max 20% bonus

        # Additional bonuses
        bonus_factors = 0.0

        # Annotation richness bonus
        if pgn_analysis.annotation_density > 0.2:
            bonus_factors += 0.05

        # Educational cues bonus
        if len(pgn_analysis.educational_cues) > 2:
            bonus_factors += 0.05

        # Famous game bonus
        if pgn_analysis.famous_game_detected:
            bonus_factors += 0.05

        # Game type bonus
        game_type_bonuses = {
            'annotated_game': 0.10,
            'complete_game': 0.05,
            'position_study': 0.08,
            'database_dump': 0.02
        }
        bonus_factors += game_type_bonuses.get(pgn_analysis.game_type, 0.0)

        return min(base_bonus + bonus_factors, 0.25)  # Cap at 25% total bonus

    def _evaluate_chunkability(self, text: str) -> float:
        """Enhanced chunkability evaluation with PGN awareness"""
        paragraphs = text.split('\n\n')
        sentences = text.split('.')

        headers = len([line for line in text.split('\n') if line.isupper() or
                       any(word in line.lower() for word in ['chapter', 'section', 'part', 'lesson', 'game'])])

        avg_paragraph_length = sum(len(p.split()) for p in paragraphs) / len(paragraphs) if paragraphs else 0
        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences) if sentences else 0

        paragraph_score = 1.0 if 40 <= avg_paragraph_length <= 200 else 0.6
        sentence_score = 1.0 if 12 <= avg_sentence_length <= 35 else 0.7
        structure_score = min(headers / 8, 1.0)

        chess_structure_bonus = 0.0
        if any(term in text.lower() for term in ['position', 'variation', 'move', 'analysis', 'game']):
            chess_structure_bonus = 0.1

        # PGN structure bonus
        pgn_bonus = 0.0
        if any(pattern in text for pattern in ['[Event', '[White', '[Black', '1.e4', '1.d4']):
            pgn_bonus = 0.05

        return min((paragraph_score + sentence_score + structure_score) / 3 + chess_structure_bonus + pgn_bonus, 1.0)

    def _evaluate_answerability(self, text: str, title: str = "") -> float:
        """Enhanced answerability evaluation with v5 improvements"""
        synthetic_questions = self._generate_enhanced_synthetic_questions(text, title)

        if not synthetic_questions:
            return 0.0

        answerable_count = 0
        for question in synthetic_questions:
            if self._can_answer_question(question, text):
                answerable_count += 1

        return answerable_count / len(synthetic_questions)

    def _generate_enhanced_synthetic_questions(self, text: str, title: str = "") -> List[str]:
        """Enhanced synthetic question generation with PGN awareness"""
        questions = []

        if title:
            questions.extend([
                f"What is {title} about?",
                f"What are the main concepts in {title}?",
                f"How does {title} work?"
            ])

        text_lower = text.lower()

        # General chess questions
        if any(term in text_lower for term in ['is defined as', 'means', 'definition', 'concept']):
            questions.append("What does this term mean?")

        if any(word in text_lower for word in ['step', 'method', 'technique', 'approach', 'strategy']):
            questions.append("How do you perform this technique?")

        if any(term in text_lower for term in ['example', 'for instance', 'such as', 'consider']):
            questions.append("What are examples of this concept?")

        # Position-specific questions
        if 'position' in text_lower:
            questions.extend([
                "What should you do in this position?",
                "How do you evaluate this position?"
            ])

        # Opening questions
        if any(word in text_lower for word in ['opening', 'defense', 'gambit']):
            questions.extend([
                "How do you play this opening?",
                "What are the main ideas in this opening?"
            ])

        # Tactical questions
        if any(word in text_lower for word in ['tactic', 'combination', 'sacrifice']):
            questions.append("How does this tactical motif work?")

        # Endgame questions
        if any(word in text_lower for word in ['endgame', 'ending', 'technique']):
            questions.append("What is the correct technique in this endgame?")

        # PGN-specific questions
        if any(pattern in text for pattern in ['1.', '2.', '[White', '[Black']):
            questions.extend([
                "What happened in this game?",
                "Why was this move played?",
                "What was the outcome of this game?"
            ])

        return questions[:18]  # Increased limit for v5

    def _can_answer_question(self, question: str, text: str) -> bool:
        """Enhanced question answerability assessment"""
        question_lower = question.lower()
        text_lower = text.lower()

        question_words = set(question_lower.split()) - {
            'what', 'how', 'why', 'when', 'where', 'is', 'are', 'do', 'does',
            'the', 'a', 'an', 'this', 'that', 'in', 'on', 'at', 'for'
        }

        matching_words = sum(1 for word in question_words if word in text_lower)

        base_threshold = 0.4
        chess_boost = 0.1 if any(word in text_lower for word in ['chess', 'move', 'position', 'piece']) else 0

        return matching_words / len(question_words) >= (base_threshold - chess_boost) if question_words else False

    def _evaluate_factual_density(self, text: str, semantic_result: SemanticAnalysisResult) -> float:
        """Enhanced factual density with v5 PGN integration"""
        factual_score = (
                semantic_result.concept_density * 0.4 +
                semantic_result.chess_domain_relevance * 0.3 +
                semantic_result.comprehensive_concept_score * 0.3
        )

        # Opinion indicators (penalties)
        opinion_indicators = ['i think', 'in my opinion', 'i believe', 'personally', 'i feel']
        opinion_count = sum(text.lower().count(indicator) for indicator in opinion_indicators)
        opinion_penalty = min(opinion_count * 0.08, 0.25)

        # Factual indicators (bonuses)
        factual_indicators = ['research shows', 'studies indicate', 'proven', 'demonstrated', 'analysis reveals']
        factual_count = sum(text.lower().count(indicator) for indicator in factual_indicators)
        factual_bonus = min(factual_count * 0.1, 0.15)

        # PGN factual bonus (games are factual by nature)
        pgn_factual_bonus = min(semantic_result.pgn_analysis.evs_score / 1000, 0.1)

        return max(0.0, min(factual_score - opinion_penalty + factual_bonus + pgn_factual_bonus, 1.0))

    def _evaluate_retrieval_friendliness(self, text: str) -> float:
        """Enhanced retrieval friendliness evaluation with v5 improvements"""
        features = {
            'cross_references': text.lower().count('see also') + text.lower().count('reference') +
                                text.lower().count('refer to'),
            'definitions': text.lower().count('definition') + text.lower().count('means') +
                           text.lower().count('is defined as'),
            'examples': text.lower().count('example') + text.lower().count('for instance') +
                        text.lower().count('such as'),
            'clear_statements': text.lower().count('therefore') + text.lower().count('because') +
                                text.lower().count('consequently'),
            'structure': text.lower().count('first') + text.lower().count('second') +
                         text.lower().count('finally'),
            'chess_specific': text.lower().count('position') + text.lower().count('move') +
                              text.lower().count('variation'),
            'games': text.lower().count('game') + text.lower().count('match'),
            'pgn_structure': text.count('[') + text.count('1.') + text.count('2.')  # PGN indicators
        }

        text_length = len(text.split())
        normalized_features = {k: v / (text_length / 1000) for k, v in features.items()}

        weights = {
            'cross_references': 1.5, 'definitions': 2.0, 'examples': 1.8,
            'clear_statements': 1.2, 'structure': 1.0, 'chess_specific': 1.3,
            'games': 1.1, 'pgn_structure': 1.4
        }

        weighted_score = sum(min(score * weights.get(feature, 1.0), 15)
                             for feature, score in normalized_features.items()) / 80

        return min(weighted_score, 1.0)

    def _calculate_overall_fitness(self, chunkability: float, answerability: float,
                                   factual_density: float, retrieval_friendliness: float) -> float:
        """Enhanced overall RAG fitness calculation with v5 weighting"""
        weights = {
            'chunkability': 0.20,
            'answerability': 0.40,
            'factual_density': 0.25,
            'retrieval_friendliness': 0.15
        }

        return (
                chunkability * weights['chunkability'] +
                answerability * weights['answerability'] +
                factual_density * weights['factual_density'] +
                retrieval_friendliness * weights['retrieval_friendliness']
        )

    def _generate_fitness_reasoning(self, chunkability: float, answerability: float,
                                    factual_density: float, retrieval_friendliness: float,
                                    pgn_bonus: float = 0.0, pgn_analysis: PGNAnalysisResult = None) -> str:
        """Enhanced fitness reasoning generation with v5 PGN integration"""
        reasons = []

        if chunkability > 0.75:
            reasons.append("Excellent chunking structure")
        elif chunkability > 0.6:
            reasons.append("Good chunking potential")

        if answerability > 0.7:
            reasons.append("High question answerability")
        elif answerability > 0.5:
            reasons.append("Moderate answerability")

        if factual_density > 0.7:
            reasons.append("Dense factual content")
        elif factual_density > 0.5:
            reasons.append("Good factual content")

        if retrieval_friendliness > 0.6:
            reasons.append("Retrieval-friendly format")

        # v5 PGN-specific reasoning
        if pgn_analysis and pgn_analysis.evs_score > 0:
            if pgn_analysis.evs_score >= 70:
                reasons.append(f"High-quality {pgn_analysis.game_type}")
            elif pgn_analysis.evs_score >= 50:
                reasons.append(f"Good {pgn_analysis.game_type}")
            else:
                reasons.append(f"Contains {pgn_analysis.game_type}")

        if pgn_bonus > 0.1:
            reasons.append("Strong PGN content bonus")
        elif pgn_bonus > 0.05:
            reasons.append("PGN content bonus")

        if pgn_analysis and pgn_analysis.famous_game_detected:
            reasons.append("Famous game context")

        if not reasons:
            return "Basic RAG suitability"

        return "; ".join(reasons)

    def _empty_fitness_result(self) -> Dict[str, Any]:
        """Return empty fitness result"""
        return {
            'overall_rag_fitness': 0.0,
            'chunkability_score': 0.0,
            'answerability_score': 0.0,
            'factual_density_score': 0.0,
            'retrieval_friendliness_score': 0.0,
            'pgn_detection_bonus': 0.0,
            'evs_score': 0.0,
            'pgn_game_type': 'no_pgn_content',
            'fitness_reasoning': 'Analysis failed'
        }


# ====================================================================================================
# COMPLETE CHESS FILE RENAMING SYSTEM WITH PROGRESS BARS - INTEGRATES WITH v5.1 ANALYZER
# ====================================================================================================

@dataclass
class RenameConfig:
    """Configuration for the renaming process"""
    source_directory: str
    output_directory: str = ""  # If empty, rename in place
    database_path: str = "chess_renaming.db"
    dry_run: bool = True
    batch_size: int = 1000
    max_workers: int = 4
    backup_enabled: bool = True
    backup_directory: str = ""
    max_filename_length: int = 120
    quality_threshold_high: int = 80  # EVS for A-tier naming
    quality_threshold_medium: int = 60  # EVS for B-tier naming
    enable_directory_organization: bool = False
    preserve_extensions: bool = True
    log_level: str = "INFO"
    resume_on_failure: bool = True
    validate_after_rename: bool = True
    rollback_file: str = "rename_rollback.json"


@dataclass
class FileRecord:
    """Record for tracking file operations"""
    id: int
    original_path: str
    new_filename: str
    new_directory: str
    content_hash: str
    file_size: int
    modification_time: float
    analysis_data: Dict[str, Any]
    evs_score: int
    content_quality: float
    game_type: str
    status: str  # discovered, analyzed, named, staged, renamed, failed, skipped
    error_message: str = ""
    processing_time: float = 0.0
    timestamp: str = ""


class FilenameGenerator:
    """Generate meaningful filenames from chess analysis"""

    def __init__(self, config: RenameConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)

        # Directory organization structure
        self.directory_structure = {
            'annotated_game': 'Annotated_Games',
            'complete_game': 'Game_Collections',
            'position_study': 'Position_Studies',
            'database_dump': 'Database_Dumps',
            'book': 'Books_and_Manuals',
            'opening_study': 'Opening_Theory',
            'endgame_study': 'Endgame_Studies',
            'article': 'Articles_and_Papers',
            'unknown': 'Unclassified'
        }

        # Forbidden characters for cross-platform compatibility
        self.forbidden_chars = ['/', '\\', ':', '*', '?', '"', '<', '>', '|', '\x00']
        self.replacement_char = '_'

    def sanitize_text(self, text: str, max_length: int = 50) -> str:
        """Clean text for use in filenames"""
        if not text:
            return "Unknown"

        # Handle macOS colon issue specifically
        text = text.replace(':', '-')

        # Unicode normalization
        text = unicodedata.normalize('NFKD', text)
        text = text.encode('ascii', 'ignore').decode('ascii')

        # Remove/replace forbidden characters
        for char in self.forbidden_chars:
            text = text.replace(char, self.replacement_char)

        # Clean up multiple separators and whitespace
        text = re.sub(r'[_\-\s]+', '_', text)
        text = re.sub(r'^[_\-]+|[_\-]+$', '', text)

        # Truncate to max length
        if len(text) > max_length:
            text = text[:max_length].rstrip('_-')

        return text if text else "Unknown"

    def extract_entities(self, analysis_result: SemanticAnalysisResult) -> Dict[str, str]:
        """Extract and format key entities from analysis"""
        entities = {}

        # Players (take top 2)
        if analysis_result.detected_players:
            players = analysis_result.detected_players[:2]
            if len(players) == 2:
                entities['players'] = f"{self.sanitize_text(players[0], 15)}_vs_{self.sanitize_text(players[1], 15)}"
            else:
                entities['players'] = self.sanitize_text(players[0], 20)

        # Primary opening
        if analysis_result.detected_openings:
            entities['opening'] = self.sanitize_text(analysis_result.detected_openings[0], 25)

        # Primary book
        if analysis_result.detected_books:
            entities['book'] = self.sanitize_text(analysis_result.detected_books[0], 30)

        # Game type
        entities['game_type'] = analysis_result.pgn_analysis.game_type

        return entities

    def determine_content_type(self, analysis_result: SemanticAnalysisResult, file_ext: str) -> str:
        """Determine primary content type"""
        pgn_analysis = analysis_result.pgn_analysis

        if pgn_analysis.evs_score > 0:
            return pgn_analysis.game_type
        elif analysis_result.detected_books:
            return "book"
        elif file_ext.lower() == '.pdf' and analysis_result.chess_domain_relevance > 0.7:
            if analysis_result.detected_openings:
                return "opening_study"
            elif "endgame" in " ".join(analysis_result.top_concepts).lower():
                return "endgame_study"
            else:
                return "article"
        else:
            return "unknown"

    def extract_year(self, analysis_result: SemanticAnalysisResult, file_path: str) -> str:
        """Extract or estimate year"""
        # Try to extract year from analysis
        year_patterns = [
            r'\b(19\d{2}|20\d{2})\b',  # Standard year patterns
        ]

        # Check top concepts and detected content for years
        text_to_search = " ".join(analysis_result.top_concepts)

        for pattern in year_patterns:
            matches = re.findall(pattern, text_to_search)
            if matches:
                return matches[0]

        # Fallback to file modification time (very unreliable)
        try:
            mtime = os.path.getmtime(file_path)
            year = datetime.fromtimestamp(mtime).year
            if 1950 <= year <= datetime.now().year:
                return str(year)
        except:
            pass

        return "Unknown"

    def generate_filename(self, analysis_result: SemanticAnalysisResult,
                          file_path: str, content_hash: str) -> Tuple[str, str]:
        """
        Generate filename from analysis result
        Returns: (filename, target_directory)
        """
        try:
            # Extract file extension
            original_ext = Path(file_path).suffix.lower()

            # Determine content type and quality tier
            content_type = self.determine_content_type(analysis_result, original_ext)
            evs_score = int(analysis_result.pgn_analysis.evs_score)
            quality_score = analysis_result.content_quality_score

            # Extract entities and metadata
            entities = self.extract_entities(analysis_result)
            year = self.extract_year(analysis_result, file_path)
            hash_short = content_hash[:8]

            # Build filename components
            filename_parts = []

            # Content type
            content_type_clean = self.sanitize_text(content_type.title().replace('_', ''), 20)
            filename_parts.append(content_type_clean)

            # Entity-specific parts based on quality
            if evs_score >= self.config.quality_threshold_high and quality_score >= 0.8:
                # High quality - detailed naming
                if entities.get('players'):
                    filename_parts.append(entities['players'])
                elif entities.get('book'):
                    filename_parts.append(entities['book'])
                elif entities.get('opening'):
                    filename_parts.append(entities['opening'])

                filename_parts.append(f"EVS{evs_score}")

                # Additional context
                if entities.get('opening') and 'players' in entities:
                    filename_parts.append(self.sanitize_text(entities['opening'], 20))

            elif evs_score >= self.config.quality_threshold_medium and quality_score >= 0.5:
                # Medium quality
                if entities.get('players'):
                    filename_parts.append(entities['players'])
                elif entities.get('book'):
                    filename_parts.append(entities['book'])
                elif entities.get('opening'):
                    filename_parts.append(entities['opening'])

                filename_parts.append(f"Q{int(quality_score * 100)}")

            elif quality_score >= 0.3:
                # Basic quality
                if entities.get('players'):
                    filename_parts.append(entities['players'].split('_')[0])  # First player only
                elif entities.get('opening'):
                    filename_parts.append(self.sanitize_text(entities['opening'], 15))

            # Year (if reasonable)
            if year != "Unknown" and year != "":
                filename_parts.append(year)

            # Hash for uniqueness
            filename_parts.append(hash_short)

            # Construct final filename
            base_name = "_".join(filename_parts)

            # Ensure reasonable length
            if len(base_name) > (self.config.max_filename_length - len(original_ext) - 5):
                # Truncate middle parts first, keep type, hash, and extension
                truncated = f"{filename_parts[0]}_{filename_parts[-1]}"
                base_name = truncated

            final_filename = base_name + original_ext

            # Determine target directory
            target_directory = ""
            if self.config.enable_directory_organization:
                target_directory = self.directory_structure.get(content_type, self.directory_structure['unknown'])

            return final_filename, target_directory

        except Exception as e:
            self.logger.error(f"Filename generation failed for {file_path}: {e}")
            # Fallback filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            fallback_name = f"Chess_File_{timestamp}_{content_hash[:8]}{Path(file_path).suffix}"
            return fallback_name, self.directory_structure.get('unknown', '')


class DatabaseManager:
    """Manage SQLite database for tracking rename operations - Enhanced with Progress Tracking"""

    def __init__(self, db_path: str):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        self._init_database()

    def _init_database(self):
        """Initialize database schema"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                         CREATE TABLE IF NOT EXISTS file_operations
                         (
                             id
                             INTEGER
                             PRIMARY
                             KEY
                             AUTOINCREMENT,
                             original_path
                             TEXT
                             UNIQUE
                             NOT
                             NULL,
                             new_filename
                             TEXT,
                             new_directory
                             TEXT,
                             content_hash
                             TEXT,
                             file_size
                             INTEGER,
                             modification_time
                             REAL,
                             analysis_data
                             TEXT,
                             evs_score
                             INTEGER,
                             content_quality
                             REAL,
                             game_type
                             TEXT,
                             status
                             TEXT,
                             error_message
                             TEXT,
                             processing_time
                             REAL,
                             timestamp
                             TEXT,
                             UNIQUE
                         (
                             content_hash,
                             new_filename
                         )
                             )
                         ''')

            # Create indexes for performance
            conn.execute('CREATE INDEX IF NOT EXISTS idx_status ON file_operations(status)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_hash ON file_operations(content_hash)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_evs ON file_operations(evs_score)')

    def insert_file_record(self, record: FileRecord):
        """Insert or update file record"""
        with sqlite3.connect(self.db_path) as conn:
            try:
                conn.execute('''
                    INSERT OR REPLACE INTO file_operations 
                    (original_path, new_filename, new_directory, content_hash, file_size,
                     modification_time, analysis_data, evs_score, content_quality, 
                     game_type, status, error_message, processing_time, timestamp)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    record.original_path, record.new_filename, record.new_directory,
                    record.content_hash, record.file_size, record.modification_time,
                    json.dumps(record.analysis_data), record.evs_score, record.content_quality,
                    record.game_type, record.status, record.error_message,
                    record.processing_time, record.timestamp
                ))
            except sqlite3.Error as e:
                self.logger.error(f"Database insert failed: {e}")

    def get_file_records(self, status: str = None, limit: int = None) -> List[FileRecord]:
        """Retrieve file records by status"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row

            query = "SELECT * FROM file_operations"
            params = []

            if status:
                query += " WHERE status = ?"
                params.append(status)

            if limit:
                query += " LIMIT ?"
                params.append(limit)

            cursor = conn.execute(query, params)
            records = []

            for row in cursor:
                analysis_data = json.loads(row['analysis_data']) if row['analysis_data'] else {}
                record = FileRecord(
                    id=row['id'],
                    original_path=row['original_path'],
                    new_filename=row['new_filename'] or "",
                    new_directory=row['new_directory'] or "",
                    content_hash=row['content_hash'] or "",
                    file_size=row['file_size'] or 0,
                    modification_time=row['modification_time'] or 0.0,
                    analysis_data=analysis_data,
                    evs_score=row['evs_score'] or 0,
                    content_quality=row['content_quality'] or 0.0,
                    game_type=row['game_type'] or "",
                    status=row['status'] or "",
                    error_message=row['error_message'] or "",
                    processing_time=row['processing_time'] or 0.0,
                    timestamp=row['timestamp'] or ""
                )
                records.append(record)

            return records

    def update_status(self, file_path: str, status: str, error_message: str = ""):
        """Update file processing status"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                         UPDATE file_operations
                         SET status        = ?,
                             error_message = ?,
                             timestamp     = ?
                         WHERE original_path = ?
                         ''', (status, error_message, datetime.now().isoformat(), file_path))

    def get_statistics(self) -> Dict[str, int]:
        """Get processing statistics"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                                  SELECT status, COUNT(*) as count
                                  FROM file_operations
                                  GROUP BY status
                                  ''')

            stats = dict(cursor.fetchall())

            # Add quality distribution
            cursor = conn.execute('''
                                  SELECT CASE
                                             WHEN evs_score >= 80 THEN 'high_quality'
                                             WHEN evs_score >= 60 THEN 'medium_quality'
                                             WHEN evs_score > 0 THEN 'basic_quality'
                                             ELSE 'no_pgn'
                                             END as quality_tier,
                                         COUNT(*) as count
                                  FROM file_operations
                                  GROUP BY quality_tier
                                  ''')

            quality_stats = dict(cursor.fetchall())
            stats.update(quality_stats)

            return stats


class FileProcessor:
    """Process individual files for analysis and renaming - Enhanced with Progress Tracking"""

    def __init__(self, config: RenameConfig):
        self.config = config
        self.analyzer = None  # Will be initialized per process
        self.filename_generator = FilenameGenerator(config)
        self.logger = logging.getLogger(__name__)

    def _init_analyzer(self):
        """Initialize analyzer (called once per process)"""
        if self.analyzer is None:
            self.analyzer = ChessSemanticAnalyzer()

    def compute_file_hash(self, file_path: str) -> str:
        """Compute SHA256 hash of file content"""
        hash_sha256 = hashlib.sha256()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except Exception as e:
            self.logger.error(f"Failed to hash {file_path}: {e}")
            return ""

    def extract_text_content_with_progress(self, file_path: str, pbar=None) -> str:
        """Extract text content with progress updates for slow operations"""
        try:
            file_ext = Path(file_path).suffix.lower()

            if pbar:
                pbar.set_description(f"Reading: {Path(file_path).name[:30]}")

            if file_ext in ['.txt', '.pgn']:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()

            elif file_ext == '.pdf':
                if pbar:
                    pbar.set_description(f"Extracting PDF: {Path(file_path).name[:25]}")

                # Enhanced PDF text extraction with progress indication
                try:
                    import PyPDF2
                    with open(file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        text = ""

                        # Show page-by-page progress for large PDFs
                        if len(reader.pages) > 10 and pbar:
                            for page_num, page in enumerate(reader.pages):
                                text += page.extract_text()
                                if page_num % 5 == 0:
                                    pbar.set_description(f"PDF page {page_num + 1}/{len(reader.pages)}")
                        else:
                            for page in reader.pages:
                                text += page.extract_text()

                        # Check if extracted text is meaningful
                        if len(text.strip()) < 50:
                            raise Exception(
                                f"PDF appears to be scanned - needs OCR (extracted only {len(text.strip())} characters)")

                        return text

                except ImportError:
                    self.logger.warning(f"PyPDF2 not available for PDF extraction: {file_path}")
                    return ""
                except Exception as e:
                    if "needs OCR" in str(e):
                        self.logger.info(f"PDF needs OCR processing: {file_path}")
                    else:
                        self.logger.warning(f"PDF extraction failed: {e}")
                    return ""
            else:
                # Try to read as text file anyway
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read(10000)  # First 10KB only
                    return content

        except Exception as e:
            self.logger.error(f"Text extraction failed for {file_path}: {e}")
            return ""

    def extract_text_content(self, file_path: str) -> str:
        """Extract text content from file (compatibility method)"""
        return self.extract_text_content_with_progress(file_path)

    def analyze_file(self, file_path: str) -> FileRecord:
        """Analyze a single file"""
        start_time = time.time()

        try:
            # Initialize analyzer if needed
            self._init_analyzer()

            # Get file metadata
            file_stat = os.stat(file_path)
            file_size = file_stat.st_size
            mod_time = file_stat.st_mtime

            # Compute content hash
            content_hash = self.compute_file_hash(file_path)
            if not content_hash:
                raise Exception("Failed to compute content hash")

            # Extract text content
            text_content = self.extract_text_content(file_path)
            if not text_content.strip():
                raise Exception("No readable text content found")

            # Perform semantic analysis
            analysis_result = self.analyzer.analyze_chess_content(
                text_content,
                surrounding_text=f"File: {Path(file_path).name}"
            )

            # Generate filename
            new_filename, target_directory = self.filename_generator.generate_filename(
                analysis_result, file_path, content_hash
            )

            # Create file record
            processing_time = time.time() - start_time

            record = FileRecord(
                id=0,  # Will be set by database
                original_path=file_path,
                new_filename=new_filename,
                new_directory=target_directory,
                content_hash=content_hash,
                file_size=file_size,
                modification_time=mod_time,
                analysis_data={
                    'detected_openings': analysis_result.detected_openings,
                    'detected_players': analysis_result.detected_players,
                    'detected_books': analysis_result.detected_books,
                    'top_concepts': analysis_result.top_concepts[:10],  # Limit for storage
                    'domain_relevance': analysis_result.chess_domain_relevance,
                    'instructional_value': analysis_result.instructional_value
                },
                evs_score=int(analysis_result.pgn_analysis.evs_score),
                content_quality=analysis_result.content_quality_score,
                game_type=analysis_result.pgn_analysis.game_type,
                status="analyzed",
                processing_time=processing_time,
                timestamp=datetime.now().isoformat()
            )

            return record

        except Exception as e:
            processing_time = time.time() - start_time
            error_record = FileRecord(
                id=0,
                original_path=file_path,
                new_filename="",
                new_directory="",
                content_hash="",
                file_size=0,
                modification_time=0.0,
                analysis_data={},
                evs_score=0,
                content_quality=0.0,
                game_type="error",
                status="failed",
                error_message=str(e),
                processing_time=processing_time,
                timestamp=datetime.now().isoformat()
            )

            return error_record


class ChessFileRenamer:
    """Main class for orchestrating the file renaming process - Enhanced with Comprehensive Progress Tracking"""

    def __init__(self, config: RenameConfig):
        self.config = config
        self.db = DatabaseManager(config.database_path)
        self.processor = FileProcessor(config)
        self.logger = self._setup_logging()

        # Statistics tracking
        self.stats = {
            'files_discovered': 0,
            'files_analyzed': 0,
            'files_renamed': 0,
            'files_failed': 0,
            'files_skipped': 0
        }

    def _setup_logging(self):
        """Setup logging configuration"""
        logging.basicConfig(
            level=getattr(logging, self.config.log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('chess_renaming.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)

    def discover_files(self) -> List[str]:
        """Discover files with progress tracking"""
        chess_extensions = {'.pgn', '.pdf', '.txt', '.doc', '.docx', '.epub', '.djvu'}
        discovered_files = []

        source_path = Path(self.config.source_directory)
        if not source_path.exists():
            raise FileNotFoundError(f"Source directory not found: {self.config.source_directory}")

        self.logger.info(f"Discovering files in {self.config.source_directory}")

        # First pass: count total files for progress bar
        print("Scanning directory structure...")
        total_files = 0
        for root, dirs, files in os.walk(source_path):
            total_files += len(files)

        # Second pass: filter chess files with progress
        with tqdm(total=total_files, desc="Discovering chess files", unit="files") as pbar:
            for root, dirs, files in os.walk(source_path):
                for file in files:
                    pbar.update(1)

                    file_path = Path(root) / file
                    if file_path.suffix.lower() in chess_extensions:
                        try:
                            if file_path.stat().st_size > 100:  # At least 100 bytes
                                discovered_files.append(str(file_path))

                                # Update description every 100 chess files found
                                if len(discovered_files) % 100 == 0:
                                    pbar.set_description(f"Found {len(discovered_files)} chess files")
                        except (OSError, IOError):
                            continue

        print(f"Discovery complete: {len(discovered_files)} chess files found")
        self.logger.info(f"Discovered {len(discovered_files)} potential chess files")
        self.stats['files_discovered'] = len(discovered_files)

        return discovered_files

    def process_files_batch(self, file_paths: List[str]) -> List[FileRecord]:
        """Process files with enhanced progress tracking"""
        print(f"Processing batch of {len(file_paths)} files...")
        self.logger.info(f"Processing batch of {len(file_paths)} files")

        if self.config.max_workers == 1:
            # Single-threaded processing with detailed progress
            records = []

            with tqdm(total=len(file_paths), desc="Analyzing files",
                      unit="files", miniters=1) as pbar:

                for i, file_path in enumerate(file_paths):
                    try:
                        # Update progress description
                        filename = Path(file_path).name
                        pbar.set_description(f"Analyzing: {filename[:40]}")

                        record = self.processor.analyze_file(file_path)
                        records.append(record)
                        self.db.insert_file_record(record)

                        # Update progress bar postfix with results
                        if record.status == "analyzed":
                            pbar.set_postfix({
                                'EVS': f"{record.evs_score}",
                                'Quality': f"{record.content_quality:.2f}",
                                'Success': f"{len([r for r in records if r.status == 'analyzed'])}/{len(records)}"
                            })
                            self.stats['files_analyzed'] += 1
                        else:
                            pbar.set_postfix({
                                'Status': 'Failed',
                                'Success': f"{len([r for r in records if r.status == 'analyzed'])}/{len(records)}"
                            })
                            self.stats['files_failed'] += 1

                        pbar.update(1)

                    except Exception as e:
                        pbar.set_postfix({'Status': f'Error: {str(e)[:20]}'})
                        self.logger.error(f"Failed to process {file_path}: {e}")
                        self.stats['files_failed'] += 1
                        pbar.update(1)

            return records

        else:
            # Multi-threaded processing with tqdm
            print(f"Using {self.config.max_workers} workers for parallel processing...")

            records = []
            successful = 0
            failed = 0

            def analyze_with_progress(file_path):
                """Wrapper function for multiprocessing"""
                return self.processor.analyze_file(file_path)

            # Use tqdm's thread_map for progress tracking with multiprocessing
            if TQDM_AVAILABLE:
                results = thread_map(
                    analyze_with_progress,
                    file_paths,
                    max_workers=self.config.max_workers,
                    desc="Parallel analysis",
                    unit="files"
                )
            else:
                # Fallback to regular ThreadPoolExecutor with manual progress
                results = []
                with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
                    future_to_file = {executor.submit(analyze_with_progress, fp): fp for fp in file_paths}

                    for i, future in enumerate(as_completed(future_to_file), 1):
                        file_path = future_to_file[future]
                        try:
                            result = future.result()
                            results.append(result)
                            print(f"Progress: {i}/{len(file_paths)} ({i / len(file_paths) * 100:.1f}%)")
                        except Exception as e:
                            print(f"Error processing {Path(file_path).name}: {e}")

            # Process results and save to database
            print("Saving analysis results to database...")

            with tqdm(results, desc="Saving to database", unit="records") as pbar:
                for record in results:
                    records.append(record)
                    self.db.insert_file_record(record)

                    if record.status == "analyzed":
                        successful += 1
                    else:
                        failed += 1

                    pbar.set_postfix({
                        'Success': successful,
                        'Failed': failed,
                        'Success Rate': f"{successful / (successful + failed) * 100:.1f}%"
                    })
                    pbar.update(1)

            self.stats['files_analyzed'] += successful
            self.stats['files_failed'] += failed

            print(f"Batch complete: {successful} analyzed, {failed} failed")
            return records

    def resolve_filename_conflicts(self):
        """Resolve filename conflicts using content-based strategies"""
        self.logger.info("Resolving filename conflicts")

        # Get all analyzed files
        records = self.db.get_file_records(status="analyzed")

        if not records:
            self.logger.info("No analyzed files found for conflict resolution")
            return

        # Group by target filename
        filename_groups = defaultdict(list)
        for record in records:
            if record.new_filename:
                key = (record.new_directory, record.new_filename)
                filename_groups[key].append(record)

        # Resolve conflicts with progress tracking
        conflicts_resolved = 0
        conflict_groups = [group for group in filename_groups.values() if len(group) > 1]

        if conflict_groups:
            with tqdm(conflict_groups, desc="Resolving filename conflicts", unit="conflicts") as pbar:
                for conflicting_records in conflict_groups:
                    # Sort by quality (EVS score, then content quality)
                    conflicting_records.sort(
                        key=lambda r: (r.evs_score, r.content_quality, r.file_size),
                        reverse=True
                    )

                    # Keep the best one as-is, modify others
                    best_record = conflicting_records[0]

                    for i, record in enumerate(conflicting_records[1:], 1):
                        # Add differentiator to filename
                        name_parts = Path(record.new_filename)
                        stem = name_parts.stem
                        suffix = name_parts.suffix

                        # Try different strategies
                        if record.evs_score > 0:
                            new_name = f"{stem}_alt{i}_EVS{record.evs_score}{suffix}"
                        else:
                            new_name = f"{stem}_alt{i}_{record.content_hash[:8]}{suffix}"

                        # Update the record
                        record.new_filename = new_name
                        self.db.insert_file_record(record)

                    conflicts_resolved += len(conflicting_records) - 1
                    pbar.set_postfix({'Resolved': conflicts_resolved})
                    pbar.update(1)

        self.logger.info(f"Resolved {conflicts_resolved} filename conflicts")

    def create_backup(self):
        """Create backup of source directory if enabled"""
        if not self.config.backup_enabled:
            return

        backup_dir = self.config.backup_directory
        if not backup_dir:
            backup_dir = f"{self.config.source_directory}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        self.logger.info(f"Creating backup at {backup_dir}")

        try:
            # Get total size for progress tracking
            total_size = sum(f.stat().st_size for f in Path(self.config.source_directory).rglob('*') if f.is_file())

            print(f"Creating backup... (Total size: {total_size / 1024 / 1024:.1f} MB)")
            shutil.copytree(self.config.source_directory, backup_dir)
            self.logger.info(f"Backup created successfully at {backup_dir}")
        except Exception as e:
            self.logger.error(f"Backup creation failed: {e}")
            if not self.config.dry_run:
                raise

    def execute_renames(self):
        """Execute renames with progress tracking"""
        if self.config.dry_run:
            self.logger.info("DRY RUN: Would rename files, but dry_run=True")
            return

        self.logger.info("Starting file rename operations")

        # Get files ready for renaming
        records = self.db.get_file_records(status="analyzed")

        if not records:
            print("No files available for renaming")
            return

        rollback_data = []
        successful_renames = 0

        with tqdm(total=len(records), desc="Renaming files", unit="files") as pbar:

            for record in records:
                try:
                    if not record.new_filename:
                        self.logger.warning(f"No new filename for {record.original_path}")
                        pbar.update(1)
                        continue

                    original_path = Path(record.original_path)

                    # Update progress description
                    pbar.set_description(f"Renaming: {original_path.name[:30]}")

                    # Determine target path
                    if self.config.output_directory:
                        target_base = Path(self.config.output_directory)
                    else:
                        target_base = original_path.parent

                    if record.new_directory:
                        target_dir = target_base / record.new_directory
                        target_dir.mkdir(parents=True, exist_ok=True)
                    else:
                        target_dir = target_base

                    target_path = target_dir / record.new_filename

                    # Check if target already exists
                    if target_path.exists() and target_path != original_path:
                        self.logger.warning(f"Target file already exists: {target_path}")
                        self.db.update_status(record.original_path, "skipped", "Target file exists")
                        pbar.update(1)
                        continue

                    # Perform the rename
                    if original_path != target_path:
                        original_path.rename(target_path)

                        # Record for rollback
                        rollback_data.append({
                            'new_path': str(target_path),
                            'original_path': str(original_path)
                        })

                        successful_renames += 1
                        self.logger.info(f"Renamed: {original_path.name} -> {record.new_filename}")

                    self.db.update_status(record.original_path, "renamed")
                    self.stats['files_renamed'] += 1

                    # Update progress postfix
                    pbar.set_postfix({
                        'Renamed': successful_renames,
                        'Rate': f"{successful_renames / max(1, (pbar.n + 1)) * 100:.1f}%"
                    })

                    pbar.update(1)

                except Exception as e:
                    self.logger.error(f"Failed to rename {record.original_path}: {e}")
                    self.db.update_status(record.original_path, "failed", str(e))
                    self.stats['files_failed'] += 1
                    pbar.update(1)
                    continue

        # Save rollback data
        if rollback_data:
            with open(self.config.rollback_file, 'w') as f:
                json.dump(rollback_data, f, indent=2)
            self.logger.info(f"Rollback data saved to {self.config.rollback_file}")

        print(f"Rename operation complete: {successful_renames} files renamed")

    def validate_renames(self):
        """Validate renamed files"""
        if not self.config.validate_after_rename or self.config.dry_run:
            return

        self.logger.info("Validating renamed files")

        records = self.db.get_file_records(status="renamed")
        validation_errors = 0

        if records:
            with tqdm(records, desc="Validating renamed files", unit="files") as pbar:
                for record in records:
                    try:
                        # Construct expected new path
                        if self.config.output_directory:
                            target_base = Path(self.config.output_directory)
                        else:
                            target_base = Path(record.original_path).parent

                        if record.new_directory:
                            target_path = target_base / record.new_directory / record.new_filename
                        else:
                            target_path = target_base / record.new_filename

                        pbar.set_description(f"Validating: {target_path.name[:30]}")

                        # Check if file exists and has correct size
                        if not target_path.exists():
                            self.logger.error(f"Renamed file missing: {target_path}")
                            validation_errors += 1
                            pbar.update(1)
                            continue

                        if target_path.stat().st_size != record.file_size:
                            self.logger.error(f"File size mismatch: {target_path}")
                            validation_errors += 1
                            pbar.update(1)
                            continue

                        pbar.set_postfix({'Errors': validation_errors})
                        pbar.update(1)

                    except Exception as e:
                        self.logger.error(f"Validation failed for {record.original_path}: {e}")
                        validation_errors += 1
                        pbar.update(1)

        if validation_errors == 0:
            self.logger.info("All renamed files validated successfully")
        else:
            self.logger.warning(f"Validation found {validation_errors} errors")

    def generate_report(self) -> str:
        """Generate a comprehensive processing report"""
        stats = self.db.get_statistics()

        report = f"""
CHESS FILE RENAMING REPORT
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

PROCESSING STATISTICS:
- Files Discovered: {self.stats['files_discovered']}
- Files Analyzed: {stats.get('analyzed', 0)}
- Files Renamed: {self.stats['files_renamed']}
- Files Failed: {stats.get('failed', 0)}
- Files Skipped: {stats.get('skipped', 0)}

QUALITY DISTRIBUTION:
- High Quality (EVS â‰¥ 80): {stats.get('high_quality', 0)}
- Medium Quality (EVS 60-79): {stats.get('medium_quality', 0)}
- Basic Quality (EVS < 60): {stats.get('basic_quality', 0)}
- No PGN Content: {stats.get('no_pgn', 0)}

CONFIGURATION:
- Source Directory: {self.config.source_directory}
- Output Directory: {self.config.output_directory or 'In-place renaming'}
- Dry Run: {self.config.dry_run}
- Backup Enabled: {self.config.backup_enabled}
- Directory Organization: {self.config.enable_directory_organization}
- Max Workers: {self.config.max_workers}
- Batch Size: {self.config.batch_size}
"""

        return report

    def run(self):
        """Main execution method with comprehensive progress tracking"""
        try:
            self.logger.info("Starting Chess File Renaming System v5.1 with Progress Tracking")

            # Create backup if enabled
            if self.config.backup_enabled:
                self.create_backup()

            # Discover files
            discovered_files = self.discover_files()
            if not discovered_files:
                self.logger.warning("No chess files discovered")
                return

            # Process files in batches
            batch_size = self.config.batch_size
            total_batches = (len(discovered_files) + batch_size - 1) // batch_size

            print(f"Processing {len(discovered_files)} files in {total_batches} batches...")

            for batch_num in range(total_batches):
                start_idx = batch_num * batch_size
                end_idx = min((batch_num + 1) * batch_size, len(discovered_files))
                batch_files = discovered_files[start_idx:end_idx]

                print(f"\n--- Batch {batch_num + 1}/{total_batches} ---")
                self.logger.info(f"Processing batch {batch_num + 1}/{total_batches}")
                self.process_files_batch(batch_files)

            # Resolve conflicts
            print("\nResolving filename conflicts...")
            self.resolve_filename_conflicts()

            # Execute renames
            print("\nExecuting file renames...")
            self.execute_renames()

            # Validate results
            print("\nValidating results...")
            self.validate_renames()

            # Generate final report
            print("\nGenerating final report...")
            report = self.generate_report()
            self.logger.info(report)

            # Write report to file
            with open('chess_renaming_report.txt', 'w') as f:
                f.write(report)

            print("Chess file renaming completed successfully!")
            self.logger.info("Chess file renaming completed successfully")

        except Exception as e:
            self.logger.error(f"Fatal error in renaming process: {e}")
            self.logger.error(traceback.format_exc())
            raise


# ====================================================================================================
# ENHANCED FILE DELETION SYSTEM WITH QUARANTINE - v5.1 ENHANCED
# ====================================================================================================

class FileDeleter:
    """Enhanced file deletion system with quarantine support - v5.1 ENHANCED"""

    def __init__(self, database_path: str):
        self.database_path = database_path
        self.quarantine_manager = QuarantineManager()
        self.logger = logging.getLogger(__name__)

    def analyze_deletion_impact(self, evs_threshold: int) -> Dict[str, Any]:
        """Analyze deletion impact with quarantine support"""
        with sqlite3.connect(self.database_path) as conn:
            conn.row_factory = sqlite3.Row

            cursor = conn.execute('''
                                  SELECT original_path, evs_score, content_quality, game_type, file_size
                                  FROM file_operations
                                  WHERE evs_score < ?
                                    AND evs_score >= 0
                                  ''', (evs_threshold,))

            files_to_quarantine = []
            total_size = 0
            deletion_by_type = defaultdict(lambda: {'count': 0, 'avg_evs': 0, 'total_evs': 0})

            for row in cursor:
                file_info = {
                    'original_path': row['original_path'],
                    'evs_score': row['evs_score'],
                    'content_quality': row['content_quality'],
                    'game_type': row['game_type'],
                    'file_size': row['file_size']
                }
                files_to_quarantine.append(file_info)
                total_size += row['file_size']

                # Track by game type
                game_type = row['game_type'] or 'unknown'
                deletion_by_type[game_type]['count'] += 1
                deletion_by_type[game_type]['total_evs'] += row['evs_score']

            # Calculate averages
            for game_type, stats in deletion_by_type.items():
                if stats['count'] > 0:
                    stats['avg_evs'] = stats['total_evs'] / stats['count']

            # Get files above threshold
            cursor = conn.execute('''
                                  SELECT COUNT(*) as keep_count, SUM(file_size) as keep_size
                                  FROM file_operations
                                  WHERE evs_score >= ?
                                  ''', (evs_threshold,))

            keep_stats = cursor.fetchone()

            return {
                'files_to_delete': len(files_to_quarantine),
                'files_to_keep': keep_stats['keep_count'] or 0,
                'size_to_delete_mb': total_size / 1024 / 1024,
                'size_to_keep_mb': (keep_stats['keep_size'] or 0) / 1024 / 1024,
                'deletion_by_type': dict(deletion_by_type),
                'quarantine_candidates': files_to_quarantine
            }

    def execute_quarantine_deletion(self, evs_threshold: int, confirm_action: bool = False) -> Optional[
        QuarantineManifest]:
        """Execute quarantine deletion with safety confirmation - v5.1 NEW FEATURE"""
        if not confirm_action:
            self.logger.error("Quarantine deletion requires explicit confirmation")
            return None

        analysis = self.analyze_deletion_impact(evs_threshold)
        candidates = analysis['quarantine_candidates']

        if not candidates:
            self.logger.info("No files found for quarantine")
            return None

        # Create quarantine session
        quarantine_id = self.quarantine_manager.create_quarantine_session(evs_threshold)

        # Move files to quarantine
        manifest = self.quarantine_manager.move_files_to_quarantine(
            candidates, quarantine_id, evs_threshold
        )

        return manifest

    def save_deletion_scripts(self, evs_threshold: int, output_dir: str = ".") -> List[str]:
        """Generate quarantine deletion scripts - v5.1 ENHANCED WITH QUARANTINE"""
        analysis = self.analyze_deletion_impact(evs_threshold)
        candidates = analysis['quarantine_candidates']

        if not candidates:
            return []

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Generate quarantine script (instead of permanent deletion)
        script_path = Path(output_dir) / f"quarantine_chess_files_{timestamp}.sh"
        analysis_path = Path(output_dir) / f"quarantine_analysis_{timestamp}.txt"

        # Generate analysis report
        with open(analysis_path, 'w') as f:
            f.write(f"""CHESS FILE QUARANTINE ANALYSIS REPORT
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Threshold: EVS < {evs_threshold}

SUMMARY:
- Files to Quarantine: {len(candidates)}
- Total Size: {analysis['size_to_delete_mb']:.1f} MB
- Files to Keep: {analysis['files_to_keep']}
- Keep Size: {analysis['size_to_keep_mb']:.1f} MB

BREAKDOWN BY CONTENT TYPE:
""")
            for game_type, stats in analysis['deletion_by_type'].items():
                f.write(f"- {game_type}: {stats['count']} files (avg EVS: {stats['avg_evs']:.1f})\n")

            f.write(f"\nFILES TO BE QUARANTINED:\n")
            for i, file_info in enumerate(candidates[:50], 1):  # Show first 50
                f.write(f"{i}. {Path(file_info['original_path']).name} (EVS: {file_info['evs_score']})\n")

            if len(candidates) > 50:
                f.write(f"... and {len(candidates) - 50} more files\n")

        # Generate quarantine script with Python integration
        with open(script_path, 'w') as f:
            f.write(f'''#!/bin/bash
# Chess File Quarantine Script - SAFE DELETION WITH RECOVERY
# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# Threshold: EVS < {evs_threshold}
# Files to quarantine: {len(candidates)}
# Total size: {analysis['size_to_delete_mb']:.1f} MB

set -e

if [ "$1" != "CONFIRM_QUARANTINE" ]; then
    echo "ERROR: This script requires CONFIRM_QUARANTINE parameter"
    echo "Usage: $0 CONFIRM_QUARANTINE"
    echo ""
    echo "QUARANTINE OPERATION SUMMARY:"
    echo "   Files to quarantine: {len(candidates)}"
    echo "   Size to quarantine: {analysis['size_to_delete_mb']:.1f} MB"
    echo "   Files will be MOVED to quarantine (recoverable)"
    echo ""
    echo "Analysis report: {analysis_path.name}"
    echo "Recovery: Files can be restored using restore command"
    echo ""
    exit 1
fi

echo "Starting quarantine operation for {len(candidates)} files..."
echo "See {analysis_path.name} for detailed analysis"

# Use Python to execute quarantine with full error handling
python3 -c "
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath('__file__')))

try:
    from {Path(__file__).stem} import FileDeleter
    deleter = FileDeleter('{self.database_path}')

    print('Executing quarantine operation...')
    manifest = deleter.execute_quarantine_deletion({evs_threshold}, confirm_action=True)

    if manifest:
        print(f'Quarantine complete!')
        print(f'   - Files quarantined: {{manifest.total_files}}')
        print(f'   - Quarantine ID: {{manifest.quarantine_id}}')
        print(f'   - Recovery command: python {Path(__file__).stem}.py --restore-quarantine {{manifest.quarantine_id}}')
    else:
        print('Quarantine operation failed')
        sys.exit(1)

except ImportError as e:
    print(f'Error: Cannot import chess system modules: {{e}}')
    print('   Make sure you are running from the correct directory')
    sys.exit(1)
except Exception as e:
    print(f'Quarantine operation failed: {{e}}')
    sys.exit(1)
"

echo "Quarantine script completed!"
''')

        os.chmod(script_path, 0o755)

        # Generate recovery script
        recovery_script_path = Path(output_dir) / f"restore_quarantine_{timestamp}.py"
        with open(recovery_script_path, 'w') as f:
            f.write(f'''#!/usr/bin/env python3
"""
Chess File Quarantine Recovery Script
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Recovers files quarantined with EVS threshold < {evs_threshold}
"""

import sys
import argparse
from pathlib import Path

def main():
    parser = argparse.ArgumentParser(description='Restore quarantined chess files')
    parser.add_argument('--list', action='store_true', help='List available quarantines')
    parser.add_argument('--restore', metavar='QUARANTINE_ID', help='Restore specific quarantine')
    parser.add_argument('--confirm', action='store_true', help='Confirm restoration')

    args = parser.parse_args()

    try:
        # Import the chess system
        from {Path(__file__).stem} import QuarantineManager

        manager = QuarantineManager()

        if args.list:
            quarantines = manager.list_quarantines()
            if quarantines:
                print("Available quarantine sessions:")
                for q in quarantines:
                    print(f"  {{q['id']}}: {{q['total_files']}} files ({{q['total_size_mb']:.1f}} MB) - {{q['creation_date']}}")
            else:
                print("No quarantine sessions found")

        elif args.restore:
            if not args.confirm:
                print("ERROR: --confirm required for restore operation")
                print(f"Usage: python {{__file__}} --restore {{args.restore}} --confirm")
                sys.exit(1)

            print(f"Restoring quarantine: {{args.restore}}")
            success = manager.restore_from_quarantine(args.restore)

            if success:
                print("Restore completed successfully!")
            else:
                print("Restore failed - check logs for details")
                sys.exit(1)
        else:
            parser.print_help()

    except ImportError as e:
        print(f"Error importing chess system: {{e}}")
        print("Make sure you're running from the correct directory")
        sys.exit(1)
    except Exception as e:
        print(f"Operation failed: {{e}}")
        sys.exit(1)

if __name__ == "__main__":
    main()
''')

        os.chmod(recovery_script_path, 0o755)

        return [str(script_path), str(analysis_path), str(recovery_script_path)]


def rollback_renames(rollback_file: str):
    """Utility function to rollback renames"""
    try:
        with open(rollback_file, 'r') as f:
            rollback_data = json.load(f)

        print(f"Rolling back {len(rollback_data)} file operations...")

        with tqdm(rollback_data, desc="Rolling back renames", unit="files") as pbar:
            for operation in rollback_data:
                new_path = Path(operation['new_path'])
                original_path = Path(operation['original_path'])

                pbar.set_description(f"Rolling back: {new_path.name[:30]}")

                if new_path.exists():
                    new_path.rename(original_path)
                    pbar.set_postfix({'Status': 'Success'})
                else:
                    pbar.set_postfix({'Status': 'File not found'})
                    print(f"Warning: File not found for rollback: {new_path}")

                pbar.update(1)

        print("Rollback completed successfully")

    except Exception as e:
        print(f"Rollback failed: {e}")


def estimate_processing_time(source_directory: str, max_workers: int = 4):
    """Estimate total processing time based on sample analysis"""
    print("Sampling files for time estimation...")

    # Discover all files
    renamer_config = RenameConfig(source_directory=source_directory, max_workers=1)
    temp_renamer = ChessFileRenamer(renamer_config)
    all_files = temp_renamer.discover_files()

    if not all_files:
        print("No files found for estimation")
        return

    # Sample up to 50 files for estimation
    sample_size = min(50, len(all_files))
    sample_files = all_files[:sample_size]

    print(f"Analyzing {sample_size} sample files...")

    start_time = time.time()
    processor = FileProcessor(renamer_config)

    successful = 0
    total_chars = 0

    with tqdm(sample_files, desc="Sample analysis", unit="files") as pbar:
        for file_path in sample_files:
            try:
                record = processor.analyze_file(file_path)
                if record.status == "analyzed":
                    successful += 1
                    # Estimate content size for scaling
                    content = processor.extract_text_content(file_path)
                    total_chars += len(content)
                pbar.update(1)
            except:
                continue

    sample_time = time.time() - start_time

    if successful == 0:
        print("No files successfully processed in sample")
        return

    # Calculate estimates
    avg_time_per_file = sample_time / successful
    avg_chars_per_file = total_chars / successful

    # Adjust for multiprocessing efficiency (diminishing returns)
    if max_workers > 1:
        efficiency = min(max_workers * 0.7, max_workers)  # 70% efficiency assumption
        estimated_total_time = (len(all_files) * avg_time_per_file) / efficiency
    else:
        estimated_total_time = len(all_files) * avg_time_per_file

    # Display estimates
    print(f"\nPROCESSING TIME ESTIMATION")
    print(f"=" * 50)
    print(f"Total files to process: {len(all_files):,}")
    print(f"Sample success rate: {successful / sample_size * 100:.1f}%")
    print(f"Avg time per file: {avg_time_per_file:.2f} seconds")
    print(f"Avg content size: {avg_chars_per_file:,.0f} characters")
    print(f"Workers: {max_workers}")
    print(f"Estimated total time: {estimated_total_time / 3600:.1f} hours")
    print(f"Estimated completion: {datetime.now() + timedelta(seconds=estimated_total_time)}")

    if estimated_total_time > 3600:  # More than 1 hour
        print(f"\nRECOMMENDATIONS:")
        print(f"   â€¢ Consider using --max-runtime to limit session length")
        print(f"   â€¢ Use --checkpoint-interval for better resumption")
        print(f"   â€¢ Process in smaller batches if memory is limited")
        if max_workers == 1:
            print(f"   â€¢ Consider increasing --workers for faster processing")


def main():
    """Command line interface with v5.1 enhancements and progress tracking"""
    parser = argparse.ArgumentParser(
        description='Chess File Renaming System v5.1 - Enhanced with IDF Weighting, Quarantine Deletion, and Progress Tracking')

    # Main operation arguments
    parser.add_argument('source_directory', nargs='?', help='Source directory containing chess files')
    parser.add_argument('--output-directory', help='Output directory (default: rename in place)')
    parser.add_argument('--dry-run', action='store_true', default=True,
                        help='Perform dry run without actual renaming')
    parser.add_argument('--execute', action='store_true',
                        help='Execute actual renaming (overrides --dry-run)')

    # Backup and safety
    parser.add_argument('--backup', action='store_true', default=True,
                        help='Create backup before renaming')
    parser.add_argument('--no-backup', action='store_true',
                        help='Disable backup creation')
    parser.add_argument('--rollback', help='Rollback file to undo previous renames')

    # Processing options
    parser.add_argument('--organize', action='store_true',
                        help='Organize files into directory structure')
    parser.add_argument('--workers', type=int, default=4,
                        help='Number of worker processes')
    parser.add_argument('--batch-size', type=int, default=1000,
                        help='Batch size for processing')

    # Database and logging
    parser.add_argument('--database', default='chess_renaming.db',
                        help='Database file path')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        default='INFO', help='Logging level')

    # v5.1 IDF Enhancement Arguments
    parser.add_argument('--calculate-idf', action='store_true',
                        help='Calculate IDF weights from corpus for enhanced analysis')
    parser.add_argument('--idf-weights-path', default='chess_idf_weights.json',
                        help='Path to IDF weights file')

    # v5.1 Quarantine Arguments
    parser.add_argument('--restore-quarantine', metavar='QUARANTINE_ID',
                        help='Restore files from quarantine session')
    parser.add_argument('--list-quarantines', action='store_true',
                        help='List available quarantine sessions')
    parser.add_argument('--purge-old-quarantines', type=int, metavar='MAX_AGE_DAYS',
                        help='Purge quarantines older than specified days')

    # Enhanced deletion functionality
    parser.add_argument('--generate-deletion-scripts', action='store_true',
                        help='Generate scripts to quarantine low-quality files')
    parser.add_argument('--deletion-threshold', type=int, default=80,
                        help='EVS threshold for quarantine (files below this score will be quarantined)')
    parser.add_argument('--deletion-analysis-only', action='store_true',
                        help='Only show quarantine analysis, do not generate scripts')
    parser.add_argument('--script-output-dir', default='.',
                        help='Directory to save quarantine scripts')
    parser.add_argument('--execute-quarantine', type=int, metavar='EVS_THRESHOLD',
                        help='Execute immediate quarantine for files below EVS threshold')

    # Time estimation and session management
    parser.add_argument('--estimate-time', action='store_true',
                        help='Estimate processing time based on sample analysis')
    parser.add_argument('--max-runtime', type=int, metavar='MINUTES',
                        help='Maximum runtime in minutes (graceful shutdown)')

    args = parser.parse_args()

    # Handle rollback operation
    if args.rollback:
        rollback_renames(args.rollback)
        return

    # Handle quarantine operations - v5.1 NEW FEATURES
    quarantine_manager = QuarantineManager()

    if args.list_quarantines:
        quarantines = quarantine_manager.list_quarantines()
        if quarantines:
            print("Available quarantine sessions:")
            print("-" * 80)
            for q in quarantines:
                print(f"ID: {q['id']}")
                print(f"  Created: {q['creation_date']}")
                print(f"  Files: {q['total_files']}")
                print(f"  Size: {q['total_size_mb']:.1f} MB")
                print(f"  Threshold: EVS < {q['deletion_threshold']}")
                print()
        else:
            print("No quarantine sessions found")
        return

    if args.restore_quarantine:
        print(f"Restoring quarantine session: {args.restore_quarantine}")
        success = quarantine_manager.restore_from_quarantine(args.restore_quarantine)
        if success:
            print("Quarantine restoration completed successfully")
        else:
            print("Quarantine restoration failed")
        return

    if args.purge_old_quarantines:
        print(f"Purging quarantines older than {args.purge_old_quarantines} days...")
        quarantine_manager.auto_purge_old_quarantines(args.purge_old_quarantines)
        print("Purge operation completed")
        return

    # Handle immediate quarantine execution
    if args.execute_quarantine:
        if not os.path.exists(args.database):
            print("ERROR: Database file not found. Run analysis first.")
            return

        print(f"EXECUTING IMMEDIATE QUARANTINE: EVS < {args.execute_quarantine}")

        deleter = FileDeleter(args.database)

        # Show analysis first
        analysis = deleter.analyze_deletion_impact(args.execute_quarantine)
        print(f"Files to quarantine: {analysis['files_to_delete']}")
        print(f"Size to quarantine: {analysis['size_to_delete_mb']:.1f} MB")

        # Require explicit confirmation
        confirm = input("Type 'CONFIRM_QUARANTINE' to proceed: ").strip()
        if confirm != 'CONFIRM_QUARANTINE':
            print("Quarantine operation cancelled")
            return

        manifest = deleter.execute_quarantine_deletion(args.execute_quarantine, confirm_action=True)
        if manifest:
            print(f"Quarantine complete: {manifest.total_files} files moved")
            print(f"Recovery command: python {__file__} --restore-quarantine {manifest.quarantine_id}")
        else:
            print("Quarantine operation failed")
        return

    # Handle deletion/quarantine script generation
    if args.generate_deletion_scripts or args.deletion_analysis_only:
        if not os.path.exists(args.database):
            print(f"ERROR: Database file not found: {args.database}")
            print("You must run the analysis first to generate quarantine scripts.")
            return

        deleter = FileDeleter(args.database)

        # Show quarantine analysis
        impact = deleter.analyze_deletion_impact(args.deletion_threshold)

        print("=" * 70)
        print("CHESS FILE QUARANTINE ANALYSIS")
        print("=" * 70)
        print(f"EVS Threshold: < {args.deletion_threshold}")
        print(f"Files to QUARANTINE: {impact['files_to_delete']}")
        print(f"Files to KEEP: {impact['files_to_keep']}")
        print(f"Size to QUARANTINE: {impact['size_to_delete_mb']:.1f} MB")
        print(f"Size to KEEP: {impact['size_to_keep_mb']:.1f} MB")

        if impact['deletion_by_type']:
            print("\nQUARANTINE BY CONTENT TYPE:")
            for game_type, stats in impact['deletion_by_type'].items():
                print(f"  {game_type:20s}: {stats['count']:4d} files (avg EVS: {stats['avg_evs']:5.1f})")

        # Calculate collection reduction percentage
        total_files = impact['files_to_delete'] + impact['files_to_keep']
        if total_files > 0:
            reduction_percent = (impact['files_to_delete'] / total_files) * 100
            print(f"\nCOLLECTION REDUCTION: {reduction_percent:.1f}% of files would be quarantined")

        print(f"\nSAFETY NOTES:")
        print("- Files will be MOVED to quarantine (not permanently deleted)")
        print("- Full recovery is possible using restore commands")
        print("- Quarantine includes detailed manifest for tracking")

        if args.deletion_analysis_only:
            print(f"\nTo generate scripts: --generate-deletion-scripts --deletion-threshold {args.deletion_threshold}")
            return

        if impact['files_to_delete'] == 0:
            print(f"\nNo files found below EVS threshold {args.deletion_threshold}")
            return

        # Generate quarantine scripts
        print(f"\nGenerating quarantine scripts for {impact['files_to_delete']} files...")

        try:
            script_files = deleter.save_deletion_scripts(
                args.deletion_threshold,
                args.script_output_dir
            )

            print(f"\nQUARANTINE SCRIPTS GENERATED:")
            for script_file in script_files:
                print(f"  {script_file}")

            print(f"\nCRITICAL SAFETY INFORMATION:")
            print("1. Files will be QUARANTINED (moved to safe location, not deleted)")
            print("2. Review the analysis report to understand what will be quarantined")
            print("3. Scripts include built-in safety confirmations")
            print("4. Full recovery is available using restore commands")
            print("5. Create a backup before running quarantine if desired")

            print(f"\nUSAGE EXAMPLE:")
            main_script = [f for f in script_files if f.endswith('.sh')][0]
            script_name = Path(main_script).name
            print(f"  bash {script_name} CONFIRM_QUARANTINE")

        except Exception as e:
            print(f"ERROR generating quarantine scripts: {e}")
            return

        return

    # Handle IDF calculation - v5.1 NEW FEATURE
    if args.calculate_idf:
        if not args.source_directory:
            print("ERROR: Source directory required for IDF calculation")
            return

        print("Starting corpus-wide IDF calculation...")
        print("This will analyze all documents to calculate term importance weights")

        # Create analyzer and collect documents
        analyzer = ChessSemanticAnalyzer()
        processor = FileProcessor(RenameConfig(source_directory=args.source_directory))

        # Discover and read documents
        chess_extensions = {'.pgn', '.pdf', '.txt', '.doc', '.docx', '.epub', '.djvu'}
        documents = []

        print(f"Discovering files in {args.source_directory}...")
        source_path = Path(args.source_directory)

        # Count total files first
        all_potential_files = []
        for root, dirs, files in os.walk(source_path):
            for file in files:
                file_path = Path(root) / file
                if file_path.suffix.lower() in chess_extensions:
                    try:
                        if file_path.stat().st_size > 100:
                            all_potential_files.append(file_path)
                    except (OSError, IOError):
                        continue

        # Process files with progress bar
        with tqdm(all_potential_files, desc="Reading documents for IDF", unit="files") as pbar:
            for file_path in all_potential_files:
                try:
                    pbar.set_description(f"Reading: {file_path.name[:40]}")
                    text_content = processor.extract_text_content_with_progress(str(file_path), pbar)
                    if text_content.strip():
                        documents.append(text_content)
                        pbar.set_postfix({'Documents': len(documents)})

                    pbar.update(1)
                except Exception as e:
                    pbar.set_postfix({'Status': f'Error: {str(e)[:20]}'})

        if not documents:
            print("No readable documents found for IDF calculation")
            return

        print(f"Performing IDF calculation on {len(documents)} documents...")
        analyzer.perform_corpus_idf_calculation(documents)

        print(f"IDF calculation complete!")
        print(f"   - Weights saved to: {args.idf_weights_path}")
        print(f"   - Enhanced analysis now available for future runs")
        print(f"   - Re-run analysis to benefit from IDF-enhanced semantic scoring")

        return

    # Time estimation feature
    if args.estimate_time and args.source_directory:
        print("Estimating processing time...")
        estimate_processing_time(args.source_directory, args.workers or 4)
        return

    # Validate source directory for rename operations
    if not args.source_directory:
        parser.print_help()
        print(f"\nERROR: source_directory is required for rename operations")
        print(f"TIP: Use --help to see all available options")
        return

    # Create configuration for rename operations
    config = RenameConfig(
        source_directory=args.source_directory,
        output_directory=args.output_directory or "",
        database_path=args.database,
        dry_run=not args.execute,  # Execute overrides dry-run
        batch_size=args.batch_size,
        max_workers=args.workers,
        backup_enabled=args.backup and not args.no_backup,
        enable_directory_organization=args.organize,
        log_level=args.log_level
    )

    # Handle max runtime
    start_time = time.time()
    max_runtime_seconds = args.max_runtime * 60 if args.max_runtime else None

    def check_time_limit():
        if max_runtime_seconds and (time.time() - start_time) > max_runtime_seconds:
            print(f"\nRuntime limit ({args.max_runtime} minutes) reached. Graceful shutdown...")
            return True
        return False

    try:
        # Create and run renamer with time limit checking
        renamer = ChessFileRenamer(config)

        if check_time_limit():
            return

        renamer.run()

    except KeyboardInterrupt:
        print("\nProcess interrupted by user. Saving current state...")
        # Add graceful shutdown logic here

    except Exception as e:
        print(f"\nFatal error: {e}")
        print("Progress has been saved. You can resume processing later.")
        raise


def print_usage_examples():
    """Print comprehensive usage examples for v5.1 with progress tracking"""
    print("""
CHESS FILE MANAGEMENT SYSTEM v5.1 - USAGE EXAMPLES (WITH PROGRESS TRACKING)

=== TIME ESTIMATION (NEW) ===
# Estimate processing time before starting
python the_evaluator.py "/path/to/chess/files" --estimate-time --workers 4

=== IDF-ENHANCED ANALYSIS (NEW v5.1) ===
# Calculate IDF weights for enhanced semantic analysis
python the_evaluator.py "/path/to/chess/files" --calculate-idf

# Run analysis with IDF-enhanced scoring
python the_evaluator.py "/path/to/chess/files" --execute --backup

=== QUARANTINE DELETION (NEW v5.1) ===
# Analyze what would be quarantined (safe preview)
python the_evaluator.py --deletion-analysis-only --deletion-threshold 70

# Generate quarantine scripts (recoverable deletion)
python the_evaluator.py --generate-deletion-scripts --deletion-threshold 80

# Execute immediate quarantine with confirmation
python the_evaluator.py --execute-quarantine 75

# List quarantine sessions
python the_evaluator.py --list-quarantines

# Restore quarantined files
python the_evaluator.py --restore-quarantine evs_below_70_20241201_143022

=== ANALYSIS AND RENAMING WITH PROGRESS ===
# 1. Dry run analysis (safe - no changes) with progress bars
python the_evaluator.py "/path/to/chess/files" --dry-run

# 2. Execute renaming with backup and organization with full progress tracking
python the_evaluator.py "/path/to/chess/files" --execute --backup --organize

# 3. Process to new directory with custom workers and progress
python the_evaluator.py "/path/to/chess/files" --output-directory "/organized/chess" --execute --workers 8

# 4. Limited runtime session with progress tracking
python the_evaluator.py "/path/to/chess/files" --execute --max-runtime 45

=== ROLLBACK AND RECOVERY ===
# Rollback previous renaming operation with progress
python the_evaluator.py --rollback rename_rollback.json

=== COMPREHENSIVE WORKFLOW EXAMPLE WITH PROGRESS ===
# Step 1: Estimate time for planning
python the_evaluator.py "/chess/collection" --estimate-time

# Step 2: Calculate IDF weights for enhanced analysis (with progress bars)
python the_evaluator.py "/chess/collection" --calculate-idf

# Step 3: Analyze and rename files with IDF enhancement and progress tracking
python the_evaluator.py "/chess/collection" --execute --backup --organize

# Step 4: Analyze quarantine candidates with detailed breakdown
python the_evaluator.py --deletion-analysis-only --deletion-threshold 80

# Step 5: Generate quarantine scripts (safe deletion) with progress
python the_evaluator.py --generate-deletion-scripts --deletion-threshold 80

# Step 6: Review and execute quarantine when ready (with progress bars)
bash quarantine_chess_files_20241201_143022.sh CONFIRM_QUARANTINE

# Step 7: Restore if needed (with progress tracking)
python the_evaluator.py --restore-quarantine evs_below_80_20241201_143022

=== SESSION MANAGEMENT FEATURES ===
# Time-limited processing (prevents session timeouts)
python the_evaluator.py "/chess/collection" --execute --max-runtime 30

# Smaller batch sizes for better memory management
python the_evaluator.py "/chess/collection" --execute --batch-size 500

# Progress tracking with detailed status updates
python the_evaluator.py "/chess/collection" --execute --workers 1  # Shows detailed per-file progress

v5.1 PROGRESS TRACKING FEATURES:
- Real-time progress bars for all operations
- ETA estimates and processing speed indicators
- Success/failure rates displayed in real-time
- Detailed status messages for current operations
- Multiprocessing-aware progress tracking
- Graceful handling of interruptions
- Time estimation before starting large operations

v5.1 SAFETY FEATURES:
- IDF weighting for more accurate quality assessment
- Quarantine system prevents permanent file loss
- Full recovery options for all operations
- Detailed analysis before any destructive operations
- Automatic backup and rollback capabilities
- Session timeout management
- Progress preservation across interruptions

INSTALLATION REQUIREMENTS:
- For progress bars: pip install tqdm
- For NLP features: pip install torch transformers sentence-transformers scikit-learn
- For PDF processing: pip install PyPDF2
""")


if __name__ == "__main__":
    import sys

    # Show usage examples if requested
    if len(sys.argv) == 2 and sys.argv[1] in ['--help-examples', '--usage-examples']:
        print_usage_examples()
        sys.exit(0)

    # Install tqdm reminder
    if not TQDM_AVAILABLE:
        print("=" * 60)
        print("PROGRESS TRACKING UNAVAILABLE")
        print("=" * 60)
        print("Install tqdm for enhanced progress bars:")
        print("  pip install tqdm")
        print("The system will work without it, but with basic progress indicators.")
        print("=" * 60)
        print()

    main()