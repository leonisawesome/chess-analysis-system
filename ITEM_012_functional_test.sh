#!/bin/bash

# ITEM-012: FUNCTIONAL TESTING OF REFACTORED SYSTEM
# Purpose: Validate that ITEM-011 refactoring (1,474â†’262 lines) didn't break anything
# Critical: Must pass before moving to ITEM-013, ITEM-014

LOG_FILE="refactoring_logs/ITEM_012_FUNCTIONAL_TEST_$(date +%Y%m%d_%H%M%S).log"
mkdir -p refactoring_logs test_results

exec > >(tee -a "$LOG_FILE") 2>&1

echo "============================================================================"
echo "ITEM-012: FUNCTIONAL TESTING OF REFACTORED SYSTEM"
echo "Started: $(date)"
echo "Log: $LOG_FILE"
echo "============================================================================"
echo ""
echo "Purpose: Validate ITEM-011 refactoring didn't break core functionality"
echo "Testing: 10 opening queries (Phase 1 + Phase 2)"
echo ""

# Test queries array
declare -a QUERIES=(
  "Explain the Italian Game opening"
  "Explain the Ruy Lopez opening"
  "Explain the King's Indian Defense"
  "Explain the Caro-Kann Defense"
  "Explain the Sicilian Defense"
  "Explain the Najdorf Variation"
  "Compare the Najdorf and Dragon variations"
  "Compare Queen's Gambit Accepted vs Declined"
  "Explain the Winawer Variation of the French Defense"
  "Explain the French Defense"
)

declare -a EXPECTED_SIGNATURES=(
  "1.e4 e5 2.Nf3 Nc6 3.Bc4"
  "1.e4 e5 2.Nf3 Nc6 3.Bb5"
  "1.d4 Nf6 2.c4 g6"
  "1.e4 c6"
  "1.e4 c5"
  "1.e4 c5 2.Nf3 d6 3.d4 cxd4 4.Nxd4 Nf6 5.Nc3 a6"
  "1.e4 c5"
  "1.d4 d5 2.c4"
  "1.e4 e6 2.d4 d5 3.Nc3 Bb4"
  "1.e4 e6"
)

# Check if Flask is running
echo "Step 1: Checking Flask server status..."
if ! curl -s http://127.0.0.1:5001/test > /dev/null 2>&1; then
    echo "âŒ Flask server not running on port 5001"
    echo ""
    echo "To start Flask server:"
    echo "  cd /Users/leon/Downloads/python/chess-analysis-system"
    echo "  python3 app.py"
    echo ""
    echo "Run this script again after Flask starts."
    exit 1
fi
echo "âœ… Flask server is running"
echo ""

# Create test results directory
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
RESULTS_DIR="test_results/ITEM_012_$TIMESTAMP"
mkdir -p "$RESULTS_DIR"
echo "Results directory: $RESULTS_DIR"
echo ""

# Initialize counters
TOTAL_TESTS=${#QUERIES[@]}
PASSED=0
FAILED=0

# Test each query
for i in "${!QUERIES[@]}"; do
  QUERY_NUM=$((i + 1))
  QUERY="${QUERIES[$i]}"
  EXPECTED="${EXPECTED_SIGNATURES[$i]}"

  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "TEST $QUERY_NUM/$TOTAL_TESTS: $QUERY"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo ""

  # Execute query
  echo "Executing query..."
  START=$(date +%s)

  RESPONSE_FILE="$RESULTS_DIR/response_$(printf "%02d" $QUERY_NUM).json"

  curl -s -X POST http://127.0.0.1:5001/query \
    -H "Content-Type: application/json" \
    -d "{\"query\": \"$QUERY\"}" \
    > "$RESPONSE_FILE"

  END=$(date +%s)
  DURATION=$((END - START))

  echo "â±  Query completed in ${DURATION}s"
  echo ""

  # Validate response
  echo "Validating response..."

  # Check if response is valid JSON
  if ! jq empty "$RESPONSE_FILE" 2>/dev/null; then
    echo "âŒ FAIL: Invalid JSON response"
    FAILED=$((FAILED + 1))
    echo "FAIL" > "$RESULTS_DIR/test_$(printf "%02d" $QUERY_NUM)_status.txt"
    continue
  fi

  # Check for error
  if jq -e '.error' "$RESPONSE_FILE" > /dev/null 2>&1; then
    ERROR=$(jq -r '.error' "$RESPONSE_FILE")
    echo "âŒ FAIL: Error in response: $ERROR"
    FAILED=$((FAILED + 1))
    echo "FAIL: $ERROR" > "$RESULTS_DIR/test_$(printf "%02d" $QUERY_NUM)_status.txt"
    continue
  fi

  # Check for answer
  if ! jq -e '.answer' "$RESPONSE_FILE" > /dev/null 2>&1; then
    echo "âŒ FAIL: No answer in response"
    FAILED=$((FAILED + 1))
    echo "FAIL: No answer" > "$RESULTS_DIR/test_$(printf "%02d" $QUERY_NUM)_status.txt"
    continue
  fi

  ANSWER=$(jq -r '.answer' "$RESPONSE_FILE")

  # Check for expected signature (for non-comparison queries)
  if [[ "$QUERY" != *"Compare"* ]] && [[ "$QUERY" != *"vs"* ]]; then
    if echo "$ANSWER" | grep -q "$EXPECTED"; then
      echo "âœ… Expected signature found: $EXPECTED"
    else
      echo "âš ï¸  WARNING: Expected signature NOT found: $EXPECTED"
      echo "   (May still be valid if alternative notation used)"
    fi
  fi

  # Check for Sicilian contamination (for non-Sicilian queries)
  if [[ "$EXPECTED" != *"1.e4 c5"* ]]; then
    if echo "$ANSWER" | grep -q "1\.e4 c5"; then
      echo "âŒ FAIL: Sicilian contamination detected (1.e4 c5 found)"
      FAILED=$((FAILED + 1))
      echo "FAIL: Sicilian contamination" > "$RESULTS_DIR/test_$(printf "%02d" $QUERY_NUM)_status.txt"
      continue
    else
      echo "âœ… No Sicilian contamination"
    fi
  fi

  # Check for diagram markers
  DIAGRAM_COUNT=$(echo "$ANSWER" | grep -o '\[DIAGRAM:' | wc -l | tr -d ' ')
  if [ "$DIAGRAM_COUNT" -gt 0 ]; then
    echo "âœ… Found $DIAGRAM_COUNT diagram markers"
  else
    echo "âš ï¸  WARNING: No diagram markers found"
  fi

  # Check response structure
  if jq -e '.sources' "$RESPONSE_FILE" > /dev/null 2>&1; then
    SOURCE_COUNT=$(jq '.sources | length' "$RESPONSE_FILE")
    echo "âœ… Response has $SOURCE_COUNT sources"
  else
    echo "âš ï¸  WARNING: No sources in response"
  fi

  # Mark as passed
  echo "âœ… PASS"
  PASSED=$((PASSED + 1))
  echo "PASS" > "$RESULTS_DIR/test_$(printf "%02d" $QUERY_NUM)_status.txt"
  echo ""
done

# Generate summary
echo "============================================================================"
echo "TEST SUMMARY"
echo "============================================================================"
echo ""
echo "Total Tests: $TOTAL_TESTS"
echo "Passed: $PASSED"
echo "Failed: $FAILED"
echo "Pass Rate: $(awk "BEGIN {printf \"%.1f\", ($PASSED/$TOTAL_TESTS)*100}")%"
echo ""

if [ $FAILED -eq 0 ]; then
  echo "ðŸŽ‰ ALL TESTS PASSED!"
  echo ""
  echo "âœ… ITEM-012 COMPLETE: Refactored system working correctly"
  echo ""
  echo "Next Steps:"
  echo "  1. Review individual test responses in: $RESULTS_DIR"
  echo "  2. Proceed to ITEM-013 (Automated Testing Infrastructure)"
  STATUS="COMPLETE"
else
  echo "âŒ $FAILED TESTS FAILED"
  echo ""
  echo "âš ï¸  ITEM-012 INCOMPLETE: Issues found in refactored system"
  echo ""
  echo "Next Steps:"
  echo "  1. Review failed tests in: $RESULTS_DIR"
  echo "  2. Fix issues before proceeding to ITEM-013"
  echo "  3. Re-run this test script"
  STATUS="FAILED"
fi
echo ""

# Create validation report
REPORT_FILE="$RESULTS_DIR/validation_report.md"
cat > "$REPORT_FILE" << EOF
# ITEM-012 Functional Testing Report

**Date:** $(date)
**Status:** $STATUS
**Pass Rate:** $(awk "BEGIN {printf \"%.1f\", ($PASSED/$TOTAL_TESTS)*100}")% ($PASSED/$TOTAL_TESTS)

## Test Results

| # | Query | Status |
|---|-------|--------|
EOF

for i in "${!QUERIES[@]}"; do
  QUERY_NUM=$((i + 1))
  QUERY="${QUERIES[$i]}"
  STATUS_FILE="$RESULTS_DIR/test_$(printf "%02d" $QUERY_NUM)_status.txt"

  if [ -f "$STATUS_FILE" ]; then
    TEST_STATUS=$(cat "$STATUS_FILE")
    if [[ "$TEST_STATUS" == "PASS" ]]; then
      STATUS_ICON="âœ…"
    else
      STATUS_ICON="âŒ"
    fi
  else
    STATUS_ICON="â“"
    TEST_STATUS="UNKNOWN"
  fi

  echo "| $QUERY_NUM | $QUERY | $STATUS_ICON $TEST_STATUS |" >> "$REPORT_FILE"
done

cat >> "$REPORT_FILE" << EOF

## Summary

- **Total Tests:** $TOTAL_TESTS
- **Passed:** $PASSED
- **Failed:** $FAILED
- **Pass Rate:** $(awk "BEGIN {printf \"%.1f\", ($PASSED/$TOTAL_TESTS)*100}")%

## Validation Criteria

Each test validated:
- âœ… Valid JSON response
- âœ… No errors in response
- âœ… Answer field present
- âœ… Expected opening signature (for non-comparison queries)
- âœ… No Sicilian contamination (for non-Sicilian openings)
- âœ… Diagram markers present
- âœ… Sources present

## Test Files

All test responses saved to: \`$RESULTS_DIR\`

## Next Steps

EOF

if [ $FAILED -eq 0 ]; then
  cat >> "$REPORT_FILE" << EOF
âœ… **All tests passed! Proceed to ITEM-013.**

The refactored system (ITEM-011) is working correctly. Ready to:
1. Build automated testing infrastructure (ITEM-013)
2. Implement middlegame solution (ITEM-014)
EOF
else
  cat >> "$REPORT_FILE" << EOF
âŒ **Fix failed tests before proceeding.**

Review failed test responses in the results directory and fix issues.
Re-run this test script after fixes are applied.
EOF
fi

echo "âœ… Validation report saved: $REPORT_FILE"
echo ""

echo "============================================================================"
echo "ITEM-012 EXECUTION COMPLETE"
echo "============================================================================"
echo ""
echo "Results Directory: $RESULTS_DIR"
echo "Validation Report: $REPORT_FILE"
echo "Log File: $LOG_FILE"
echo ""
echo "View report: cat $REPORT_FILE"
echo "============================================================================"
